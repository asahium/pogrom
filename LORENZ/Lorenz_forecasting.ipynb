{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUuORlyukRq4"
   },
   "source": [
    "# 0 Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phQ5ad0WL2Rj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AdgkcfHL2rP",
    "outputId": "ccfeaa3c-4832-4901-8c73-13b925b01d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUaPgxiqoHec",
    "outputId": "b8fbcda0-bf96-4aeb-8cf3-f7c242e8b690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IBbXRofkZKT"
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# loading and saving jupyter session\n",
    "load_session = True\n",
    "save_session = True\n",
    "\n",
    "# using collab\n",
    "\n",
    "path_to_load_session = '/content/drive/My Drive/envs/last_env.db'\n",
    "\n",
    "path_to_save_session = 'lorenz_forecasting_env.db'\n",
    "\n",
    "if load_session:\n",
    "    dill._dill._reverse_typemap['ClassType'] = type\n",
    "    dill.load_session(path_to_load_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNpzRp9kka-g"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pdb\n",
    "import dill\n",
    "from sklearn.datasets import make_blobs\n",
    "from itertools import combinations, product\n",
    "from scipy.special import gamma\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import f1_score, confusion_matrix, silhouette_score, davies_bouldin_score\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6b6Kg5u8kmxf"
   },
   "outputs": [],
   "source": [
    "# data generation \n",
    "\n",
    "N = 5\n",
    "WINDOW_MIN = 8\n",
    "WINDOW = 15\n",
    "\n",
    "TRAIN_SIZE = 5000\n",
    "VAL_SIZE = 200\n",
    "TEST_SIZE = 200\n",
    "PTS = 100\n",
    "\n",
    "train_start = 0\n",
    "train_end = TRAIN_SIZE\n",
    "\n",
    "val_init = TRAIN_SIZE + WINDOW - 1\n",
    "val_start = val_init - 1\n",
    "val_end = val_start + VAL_SIZE\n",
    "\n",
    "test_init = val_end + WINDOW - 1\n",
    "test_start = test_init - 1\n",
    "test_end = test_start + TEST_SIZE - WINDOW\n",
    "\n",
    "# clusterize data\n",
    "\n",
    "WISHART_K = 4\n",
    "WISHART_H = 0.2\n",
    "\n",
    "# generate predictions\n",
    "\n",
    "STEPS, EPS = 50, 0.05\n",
    "# STEPS, EPS = 60, 0.025\n",
    "\n",
    "Q_VALUE = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3qKtHV3GrHf"
   },
   "source": [
    "\n",
    "# 1 Functions part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUO5luGMMF5R"
   },
   "source": [
    "## lorenz series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3py1KrkVpnFS"
   },
   "outputs": [],
   "source": [
    "class Lorentz:\n",
    "    def __init__(self, s = 10, r = 28, b = 8/3):\n",
    "        self.s = s\n",
    "        self.r = r\n",
    "        self.b = b\n",
    "\n",
    "    #Differential equations of a Lorenz System\n",
    "    def X(self, x, y, s):\n",
    "        return s * (y - x)\n",
    "\n",
    "    def Y(self, x, y, z, r):\n",
    "        return (-x) * z + r * x - y\n",
    "\n",
    "    def Z(self, x, y, z, b):\n",
    "        return x * y - b * z\n",
    "\n",
    "    #RK4 for the differential equations\n",
    "    def RK4(self, x, y, z, s, r, b, dt):\n",
    "        k_1 = self.X(x, y, s)\n",
    "        l_1 = self.Y(x, y, z, r)\n",
    "        m_1 = self.Z(x, y, z, b)\n",
    "\n",
    "        k_2 = self.X((x + k_1 * dt * 0.5), (y + l_1 * dt * 0.5), s)\n",
    "        l_2 = self.Y((x + k_1 * dt * 0.5), (y + l_1 * dt * 0.5), (z + m_1 * dt * 0.5), r)\n",
    "        m_2 = self.Z((x + k_1 * dt * 0.5), (y + l_1 * dt * 0.5), (z + m_1 * dt * 0.5), b)\n",
    "\n",
    "        k_3 = self.X((x + k_2 * dt * 0.5), (y + l_2 * dt * 0.5), s)\n",
    "        l_3 = self.Y((x + k_2 * dt * 0.5), (y + l_2 * dt * 0.5), (z + m_2 * dt * 0.5), r)\n",
    "        m_3 = self.Z((x + k_2 * dt * 0.5), (y + l_2 * dt * 0.5), (z + m_2 * dt * 0.5), b)\n",
    "\n",
    "        k_4 = self.X((x + k_3 * dt), (y + l_3 * dt), s)\n",
    "        l_4 = self.Y((x + k_3 * dt), (y + l_3 * dt), (z + m_3 * dt), r)\n",
    "        m_4 = self.Z((x + k_3 * dt), (y + l_3 * dt), (z + m_3 * dt), b)\n",
    "\n",
    "        x += (k_1 + 2 * k_2 + 2 * k_3 + k_4) * dt * (1/6)\n",
    "        y += (l_1 + 2 * l_2 + 2 * l_3 + l_4) * dt * (1/6)\n",
    "        z += (m_1 + 2 * m_2 + 2 * m_3 + m_4) * dt * (1/6)\n",
    "\n",
    "        return (x, y, z)\n",
    "\n",
    "    def generate(self, dt, steps):\n",
    "        #Initial values and Parameters\n",
    "        x_0, y_0, z_0 = 1, 1, 1\n",
    "\n",
    "        #RK4 iteration\n",
    "        x_list = [x_0]\n",
    "        y_list = [y_0]\n",
    "        z_list = [z_0]\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        while i < steps:\n",
    "            x = x_list[i]\n",
    "            y = y_list[i]\n",
    "            z = z_list[i]\n",
    "\n",
    "            position = self.RK4(x, y, z, self.s, self.r, self.b, dt)\n",
    "\n",
    "            x_list.append(position[0])\n",
    "            y_list.append(position[1])\n",
    "            z_list.append(position[2])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        x_array = np.array(x_list)\n",
    "        y_array = np.array(y_list)\n",
    "        z_array = np.array(z_list)\n",
    "\n",
    "        return x_array, y_array, z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10139/2506250848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_array' is not defined"
     ]
    }
   ],
   "source": [
    "x_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMMOk0wPMF5g"
   },
   "source": [
    "## wishart clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NIQ3FiuMF5k"
   },
   "outputs": [],
   "source": [
    "def volume(r, m):\n",
    "    return np.pi ** (m / 2) * r ** m / gamma(m / 2 + 1)\n",
    "\n",
    "def significant(cluster, h, p):\n",
    "    max_diff = max(abs(p[i] - p[j]) for i, j in product(cluster, cluster))\n",
    "\n",
    "    # print(max_diff)\n",
    "    return max_diff >= h\n",
    "\n",
    "def partition(dist, l, r, order):\n",
    "    if l == r:\n",
    "        return l\n",
    "\n",
    "    pivot = dist[order[(l + r) // 2]]\n",
    "    left, right = l - 1, r + 1\n",
    "    while True:\n",
    "        while True:\n",
    "            left += 1\n",
    "            if dist[order[left]] >= pivot:\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "            right -= 1\n",
    "            if dist[order[right]] <= pivot:\n",
    "                break\n",
    "\n",
    "        if left >= right:\n",
    "            return right\n",
    "\n",
    "        order[left], order[right] = order[right], order[left]\n",
    "\n",
    "def nth_element(dist, order, k):\n",
    "    l, r = 0, len(order) - 1\n",
    "    while True:\n",
    "        if l == r:\n",
    "            break\n",
    "        m = partition(dist, l, r, order)\n",
    "        if m < k:\n",
    "            l = m + 1\n",
    "        elif m >= k:\n",
    "            r = m\n",
    "\n",
    "def get_clustering(x, k, h, verbose=True):\n",
    "    n = len(x)\n",
    "    if isinstance(x[0], list):\n",
    "        m = len(x[0])\n",
    "    else:\n",
    "        m = 1\n",
    "    dist = squareform(pdist(x))\n",
    "\n",
    "    dk = []\n",
    "    for i in range(n):\n",
    "        order = list(range(n))\n",
    "        nth_element(dist[i], order, k - 1)\n",
    "        dk.append(dist[i][order[k - 1]])\n",
    "\n",
    "    # print(dk)\n",
    "\n",
    "    p = [k / (volume(dk[i], m) * n) for i in range(n)]\n",
    "\n",
    "    w = np.full(n, 0)\n",
    "    completed = {0: False}\n",
    "    last = 1\n",
    "    vertices = set()\n",
    "    for d, i in sorted(zip(dk, range(n))):\n",
    "        neigh = set()\n",
    "        neigh_w = set()\n",
    "        clusters = defaultdict(list)\n",
    "        for j in vertices:\n",
    "            if dist[i][j] <= dk[i]:\n",
    "                neigh.add(j)\n",
    "                neigh_w.add(w[j])\n",
    "                clusters[w[j]].append(j)\n",
    "\n",
    "        vertices.add(i)\n",
    "        if len(neigh) == 0:\n",
    "            w[i] = last\n",
    "            completed[last] = False\n",
    "            last += 1\n",
    "        elif len(neigh_w) == 1:\n",
    "            wj = next(iter(neigh_w))\n",
    "            if completed[wj]:\n",
    "                w[i] = 0\n",
    "            else:\n",
    "                w[i] = wj\n",
    "        else:\n",
    "            if all(completed[wj] for wj in neigh_w):\n",
    "                w[i] = 0\n",
    "                continue\n",
    "            significant_clusters = set(wj for wj in neigh_w if significant(clusters[wj], h, p))\n",
    "            if len(significant_clusters) > 1:\n",
    "                w[i] = 0\n",
    "                for wj in neigh_w:\n",
    "                    if wj in significant_clusters:\n",
    "                        completed[wj] = (wj != 0)\n",
    "                    else:\n",
    "                        for j in clusters[wj]:\n",
    "                            w[j] = 0\n",
    "            else:\n",
    "                if len(significant_clusters) == 0:\n",
    "                    s = next(iter(neigh_w))\n",
    "                else:\n",
    "                    s = next(iter(significant_clusters))\n",
    "                w[i] = s\n",
    "                for wj in neigh_w:\n",
    "                    for j in clusters[wj]:\n",
    "                        w[j] = s\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm3sSMDJSJB3"
   },
   "outputs": [],
   "source": [
    "class WishartClusterization(object):\n",
    "    def __init__(self, k, h):\n",
    "        self.k = k\n",
    "        self.h = h\n",
    "        \n",
    "    \n",
    "    def fit(self, x):\n",
    "        n = len(x)\n",
    "        if isinstance(x[0], list):\n",
    "            m = len(x[0])\n",
    "        else:\n",
    "            m = 1\n",
    "        dist = squareform(pdist(x))\n",
    "\n",
    "        dk = []\n",
    "        for i in range(n):\n",
    "            order = list(range(n))\n",
    "            nth_element(dist[i], order, self.k - 1)\n",
    "            dk.append(dist[i][order[self.k - 1]])\n",
    "\n",
    "        # print(dk)\n",
    "\n",
    "        p = [self.k / (volume(dk[i], m) * n) for i in range(n)]\n",
    "\n",
    "        w = np.full(n, 0)\n",
    "        completed = {0: False}\n",
    "        last = 1\n",
    "        vertices = set()\n",
    "        for d, i in sorted(zip(dk, range(n))):\n",
    "            neigh = set()\n",
    "            neigh_w = set()\n",
    "            clusters = defaultdict(list)\n",
    "            for j in vertices:\n",
    "                if dist[i][j] <= dk[i]:\n",
    "                    neigh.add(j)\n",
    "                    neigh_w.add(w[j])\n",
    "                    clusters[w[j]].append(j)\n",
    "\n",
    "            vertices.add(i)\n",
    "            if len(neigh) == 0:\n",
    "                w[i] = last\n",
    "                completed[last] = False\n",
    "                last += 1\n",
    "            elif len(neigh_w) == 1:\n",
    "                wj = next(iter(neigh_w))\n",
    "                if completed[wj]:\n",
    "                    w[i] = 0\n",
    "                else:\n",
    "                    w[i] = wj\n",
    "            else:\n",
    "                if all(completed[wj] for wj in neigh_w):\n",
    "                    w[i] = 0\n",
    "                    continue\n",
    "                significant_clusters = set(wj for wj in neigh_w if significant(clusters[wj], self.h, p))\n",
    "                if len(significant_clusters) > 1:\n",
    "                    w[i] = 0\n",
    "                    for wj in neigh_w:\n",
    "                        if wj in significant_clusters:\n",
    "                            completed[wj] = (wj != 0)\n",
    "                        else:\n",
    "                            for j in clusters[wj]:\n",
    "                                w[j] = 0\n",
    "                else:\n",
    "                    if len(significant_clusters) == 0:\n",
    "                        s = next(iter(neigh_w))\n",
    "                    else:\n",
    "                        s = next(iter(significant_clusters))\n",
    "                    w[i] = s\n",
    "                    for wj in neigh_w:\n",
    "                        for j in clusters[wj]:\n",
    "                            w[j] = s\n",
    "        self.labels_ = w\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDHLmrg40qtl"
   },
   "source": [
    "## generate cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMvlBtj5MF7E"
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def generate_centers(x_trains, WISHART_K=4, WISHART_H=0.2):\n",
    "    ws = {}\n",
    "    for pattern, train in x_trains.items():\n",
    "        ws[pattern] = get_clustering(train, WISHART_K, WISHART_H)\n",
    "\n",
    "    centers = {}\n",
    "    \n",
    "    for pattern, w in ws.items():\n",
    "        sorted_by_cluster = sorted(range(len(w)), key=lambda x: w[x])\n",
    "        for wi, cluster in groupby(sorted_by_cluster, lambda x: w[x]):\n",
    "            cluster = list(cluster)\n",
    "            center = np.full(N, 0.0)\n",
    "            for i in cluster:\n",
    "\n",
    "                center += x_trains[pattern][i]\n",
    "            centers.setdefault(pattern, []).append(center / len(cluster))\n",
    "\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCqBKw-cMF5t"
   },
   "source": [
    "## windows functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gRecS4FRMF5v"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_subsequences(window, num, short=False):\n",
    "    values = list(range(window))\n",
    "    result = []\n",
    "    if short:\n",
    "        for subseq in itertools.combinations(values, num):\n",
    "            diff = WINDOW - WINDOW_MIN\n",
    "            result.append(tuple([num + diff for num in subseq]))\n",
    "    else:\n",
    "        for subseq in itertools.combinations(values, num):\n",
    "            result.append(subseq)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDUqMzWNMF51"
   },
   "source": [
    "## sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7PbgPEKMF52"
   },
   "outputs": [],
   "source": [
    "def str_subseq(subseq):\n",
    "    if not subseq:\n",
    "        return '<None>'\n",
    "    return ','.join(map(str, subseq))\n",
    "\n",
    "def gen_sample_in_point(values, window, pattern, pos):\n",
    "    # наложить шаблон \n",
    "    if pos - window + 1 + pattern[0] >= 0:\n",
    "        vals = []\n",
    "        bad = values[pos] == None\n",
    "        for j in pattern:\n",
    "            val = values[pos - window + 1 + j]\n",
    "            if val == None:\n",
    "                bad = True\n",
    "                break\n",
    "            vals.append(val)\n",
    "        if bad:\n",
    "            return None\n",
    "        vals.append(values[pos])\n",
    "        return vals\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def gen_sample_in_point_with_q(values, window, pattern, pos):\n",
    "    # наложить шаблон \n",
    "    if pos - window + 1 + pattern[0] >= 0:\n",
    "        vals = []\n",
    "        bad = values[pos][0] == None\n",
    "        for j in pattern:\n",
    "            val = values[pos - window + 1 + j]\n",
    "            if val[0] == None:\n",
    "                bad = True\n",
    "                break\n",
    "            vals.append(val)\n",
    "        if bad:\n",
    "            return None\n",
    "        vals.append(values[pos])\n",
    "        return vals\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def generate_sample(values, window, pattern, put_none=False):\n",
    "    result = []\n",
    "    for i in range(len(values)):\n",
    "        res = gen_sample_in_point(values, window, pattern, i)\n",
    "        if res == None:\n",
    "            if put_none:\n",
    "                result.append(res)\n",
    "        else:\n",
    "            result.append(res)\n",
    "    return result\n",
    "\n",
    "def aggr(pts):\n",
    "    if not pts:\n",
    "        return None\n",
    "    sum_weight = sum(map(lambda center: center[1], pts))\n",
    "    pred = sum(map(lambda center: center[0] * center[1], pts))\n",
    "    return pred / sum_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfJ07uSRMF59"
   },
   "source": [
    "## errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMjyXf2rMF6C"
   },
   "outputs": [],
   "source": [
    "def calc_mae(actual, predictions, step):\n",
    "    result = 0\n",
    "    predictable = 0\n",
    "    for start_point, preds in predictions.items():\n",
    "        if preds[start_point + step]:\n",
    "            result += abs(actual[start_point + step] - preds[start_point + step])\n",
    "            predictable += 1\n",
    "    if predictable == 0:\n",
    "        return None\n",
    "    return result / predictable\n",
    "\n",
    "def calc_rmse(actual, predictions, step):\n",
    "    result = 0\n",
    "    predictable = 0\n",
    "    for start_point, preds in predictions.items():\n",
    "        if preds[start_point + step]:\n",
    "            result += np.square(actual[start_point + step] - preds[start_point + step])\n",
    "            predictable += 1\n",
    "    if predictable == 0:\n",
    "        return None\n",
    "    return sqrt(result / predictable)\n",
    "\n",
    "def calc_non_predictable(actual, predictions, step):\n",
    "    result = 0\n",
    "    for start_point, preds in predictions.items():\n",
    "        if not preds[start_point + step]:\n",
    "            result += 1\n",
    "    return result / len(predictions) * 100\n",
    "\n",
    "def calc_predictable(actual, predictions, step):\n",
    "    result = 0\n",
    "    for start_point, preds in predictions.items():\n",
    "        if preds[start_point + step]:\n",
    "            result += 1\n",
    "    return result / len(predictions) * 100\n",
    "\n",
    "def calc_metric_for_steps(actual, predictions, calc_metric):\n",
    "    result = [None]\n",
    "    for step in range(1, STEPS + 1):\n",
    "\n",
    "        result.append(calc_metric(actual, predictions, step))\n",
    "    return result\n",
    "\n",
    "def calc_mae_for_steps(actual, predictions):\n",
    "    return calc_metric_for_steps(actual, predictions, calc_mae)\n",
    "\n",
    "def calc_rmse_for_steps(actual, predictions):\n",
    "    return calc_metric_for_steps(actual, predictions, calc_rmse)\n",
    "\n",
    "def calc_non_predictable_for_steps(actual, predictions):\n",
    "    return calc_metric_for_steps(actual, predictions, calc_non_predictable)\n",
    "\n",
    "def calc_predictable_for_steps(actual, predictions):\n",
    "    return calc_metric_for_steps(actual, predictions, calc_predictable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwLoBCbViUdd"
   },
   "source": [
    "## generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rfyaLQB5f2o"
   },
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "\n",
    "def generate_predictions(centers, deamon=None, return_set_pred=False, real_mode='test',\n",
    "                          EPS=0.05, Q_VALUE=0.99):\n",
    "    preds = {}\n",
    "    set_preds = {}\n",
    "\n",
    "    if real_mode == 'test':\n",
    "        end_point = val_end\n",
    "        init_point = test_init\n",
    "    else:\n",
    "        end_point = train_end\n",
    "        init_point = val_init\n",
    "\n",
    "    for start_point in tqdm(range(PTS)):\n",
    "        \n",
    "        # initialize empty\n",
    "        preds[start_point] = [None] * (start_point + 1)\n",
    "        if return_set_pred:\n",
    "            set_preds[start_point] = [None] * (start_point + 1)\n",
    "\n",
    "        # current window\n",
    "        wind = list(map(lambda x: (x, 1), xs[end_point + start_point : init_point + start_point]))\n",
    "\n",
    "        for step in range(1, STEPS + 1):\n",
    "            x_tests_for_point = {}\n",
    "            for pattern in patterns:\n",
    "                \n",
    "                key = str_subseq(pattern + (WINDOW - 1,)) \n",
    "                sample = gen_sample_in_point_with_q(np.concatenate([wind, [(0, 0)]]), \n",
    "                                                    WINDOW, pattern, len(wind))\n",
    "                if not sample:\n",
    "                    x_tests_for_point[key] = None\n",
    "                else:\n",
    "                    x_tests_for_point[key] = sample\n",
    "\n",
    "            chosen_centers = []\n",
    "            for pattern, centers_values in centers.items():\n",
    "                if not x_tests_for_point[pattern]:\n",
    "                    continue\n",
    "                vector = np.array(x_tests_for_point[pattern][:-1])[:, 0]\n",
    "                q_values = np.array(x_tests_for_point[pattern][:-1])[:, 1]\n",
    "\n",
    "                for center in centers_values:\n",
    "                    dist = euclidean(vector, center[:-1])\n",
    "                    if dist < EPS:\n",
    "                        weight_d = (EPS - dist) / EPS\n",
    "                        weight_q = np.mean(q_values) * Q_VALUE\n",
    "                        chosen_centers.append((pattern, center, weight_d, weight_q))\n",
    "\n",
    "            last_points = list(map(lambda center: (center[1][-1], center[2], center[3], center[0]), \n",
    "                                  chosen_centers))\n",
    "            \n",
    "            # deamon predict\n",
    "            result_point = deamon.predict(start_point, step, last_points)\n",
    "            preds[start_point].append(result_point)\n",
    "\n",
    "            if return_set_pred:\n",
    "                set_preds[start_point].append(last_points)\n",
    "\n",
    "            \n",
    "            if result_point:\n",
    "                q_value = np.mean(np.array(list(map(lambda center: center[2], \n",
    "                                  chosen_centers))))\n",
    "            else:\n",
    "                q_value = None\n",
    "            \n",
    "            # move the window\n",
    "            wind = np.concatenate([wind[1:], [(result_point, q_value)]])\n",
    "\n",
    "    deamon.predicted = True\n",
    "\n",
    "    if return_set_pred:\n",
    "        return preds, set_preds\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZcurf-HlLIq"
   },
   "source": [
    "## aggregate predictions with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUVcpe6_lQtw"
   },
   "outputs": [],
   "source": [
    "def simple_aggr(pts):\n",
    "  if not pts:\n",
    "        return None\n",
    "  return np.mean(np.array(list(map(lambda center: center[0], pts))))\n",
    "\n",
    "def aggr_d(pts):\n",
    "    # weighted sum by distance\n",
    "    if not pts:\n",
    "        return None\n",
    "    sum_weight = sum(map(lambda center: center[1], pts))\n",
    "    pred = sum(map(lambda center: center[0] * center[1], pts))\n",
    "    return pred / sum_weight\n",
    "\n",
    "def aggr_q(pts):\n",
    "    # weighted sum by q-value\n",
    "    if not pts:\n",
    "        return None\n",
    "    sum_weight = sum(map(lambda center: center[2], pts))\n",
    "    pred = sum(map(lambda center: center[0] * center[2], pts))\n",
    "    return pred / sum_weight\n",
    "\n",
    "def aggr_mix(pts):\n",
    "    if not pts:\n",
    "        return None\n",
    "    sum_weight = sum(map(lambda center: center[1] * center[2], pts))\n",
    "    pred = sum(map(lambda center: center[0] * center[1] * center[2], pts))\n",
    "    return pred / sum_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xcp_tfOMF6K"
   },
   "source": [
    "## demon metrics visualizion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBz7i_S-MF6L"
   },
   "outputs": [],
   "source": [
    "def add_preds(preds, daemon, filtered_preds):\n",
    "    preds[daemon] = filtered_preds\n",
    "\n",
    "def get_metrics(daemons, actual, return_values=False, plot=True):\n",
    "    preds = {}\n",
    "    \n",
    "    for daemon in daemons:\n",
    "        add_preds(preds, daemon[1], daemon[0].get_predictions())\n",
    "    \n",
    "    mae, rmse, non_pred = plot_daemons_result(actual, preds, plot=plot)\n",
    "\n",
    "    if return_values:\n",
    "        return mae, rmse, non_pred\n",
    "\n",
    "def print_metrics_for_subplot(metrics, ax, title):\n",
    "    for values, label in metrics:\n",
    "        ax.plot(values[:-1], label=label)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='best')\n",
    "    #ax.set_xticks([1, 5, 10, 15, 20, 25, 30])\n",
    "    ax.set_xticks(np.arange(0, STEPS + 1, 5))\n",
    "    ax.grid()\n",
    "\n",
    "def print_metric_for_subplot(func, metric_name, actual, daemons_predictions, ax, plot=True):\n",
    "    metrics = []\n",
    "    for label, pred in daemons_predictions.items():\n",
    "        metrics.append([func(actual, pred), label])\n",
    "    if plot:\n",
    "        print_metrics_for_subplot(metrics, ax, metric_name)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def plot_daemons_result(actual, daemons_predictions, plot=True):\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(20,10))\n",
    "        fig.tight_layout()\n",
    "    else:\n",
    "        ax = np.zeros((2,2))\n",
    "    mae = print_metric_for_subplot(calc_mae_for_steps, 'MAE', actual, daemons_predictions, ax[0][0], plot=plot)\n",
    "    rmse = print_metric_for_subplot(calc_rmse_for_steps, 'RMSE', actual, daemons_predictions, ax[0][1], plot=plot)\n",
    "    non_pred = print_metric_for_subplot(calc_non_predictable_for_steps, 'non-predictable (%)', actual, daemons_predictions, ax[1][0], plot=plot)\n",
    "    print_metric_for_subplot(calc_predictable_for_steps, 'predictable (%)', actual, daemons_predictions, ax[1][1], plot=plot)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "    return mae, rmse, non_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zB5eyJIMF73"
   },
   "source": [
    "## divergence visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "V41SFOsg9_lW",
    "outputId": "5b714a23-411d-4152-ecc8-fbf6cdf4d7f7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e3210756c33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m def visualize_point(preds, point, real_vals=x_test, plot_all_points=None, plot_tube_points=None,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     highlight_point=None, plot_res_tube=None, offset=3):\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'orange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize_point(preds, point, real_vals=x_test, plot_all_points=None, plot_tube_points=None,\n",
    "                    highlight_point=None, plot_res_tube=None, offset=3):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colors=['green', 'red', 'orange']\n",
    "\n",
    "    limits_real = [point - offset, point + STEPS + offset]\n",
    "    plt.plot(\n",
    "        range(limits_real[0], limits_real[1]),\n",
    "        real_vals[limits_real[0]:limits_real[1]], \n",
    "        label='real values'\n",
    "    )\n",
    "\n",
    "    limits_predictions = [point, point + STEPS]\n",
    "    for i, pred in enumerate(preds):\n",
    "        plt.plot(\n",
    "            range(limits_predictions[0], limits_predictions[1]),\n",
    "            pred[0].get_predictions()[point][limits_predictions[0]:limits_predictions[1]], \n",
    "            label=pred[1], \n",
    "            marker='o', \n",
    "            markersize=2,\n",
    "            c=colors[i]\n",
    "        )\n",
    "\n",
    "        if plot_all_points:\n",
    "            for step in plot_all_points:\n",
    "                raw_preds = pred[0].get_set_predictions()[point][point + step]\n",
    "                set_preds = list(map(lambda x: x[0], raw_preds))\n",
    "                plt.scatter([point + step for i in range(len(set_preds))], \n",
    "                            set_preds, alpha=0.2, color='red')\n",
    "    if highlight_point:\n",
    "        plt.plot(\n",
    "            point + highlight_point,\n",
    "            pred[0].get_predictions()[point][point + highlight_point], \n",
    "            label='bad', \n",
    "            marker='o', \n",
    "            markersize=10, \n",
    "            color=\"purple\"\n",
    "        )\n",
    "\n",
    "    if plot_res_tube is not None:\n",
    "        plt.plot(range(limits_predictions[0] + 1, limits_predictions[1] + 1), plot_res_tube, label='tube avg')\n",
    "\n",
    "    if plot_tube_points is not None:\n",
    "        for tr in plot_tube_points:\n",
    "            plt.plot(range(limits_predictions[0] + 1, limits_predictions[1] + 1), tr, alpha=0.3, linestyle='--')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.scatter([point], real_vals[point], label='start')\n",
    "    plt.axvline(x=(point + 1), linewidth=0.5, color='r', label=\"step 1\")\n",
    "    for mark in range(5, STEPS + 1, 5):\n",
    "        plt.axvline(x=(point + mark), linewidth=0.5, color='r', label=\"step \" + str(mark))\n",
    "\n",
    "    plt.title(\"Divergence\")\n",
    "    plt.xlabel(\"point\")\n",
    "    plt.ylabel(\"Lorenz value\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNk9YhFfF7V5"
   },
   "source": [
    "## histogram utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TW4RKkb4YSoc"
   },
   "outputs": [],
   "source": [
    "def get_weights(start, step, mode, set_preds):\n",
    "    preds = list(map(lambda x: x[0], set_preds[start][start + step]))\n",
    "    pred = simple_aggr(set_preds[start][start + step])\n",
    "\n",
    "    if mode == 'simple':\n",
    "        weights = np.ones(len(preds))\n",
    "    elif mode == 'q-value':\n",
    "        weights = list(map(lambda x: x[2], set_preds[start][start + step]))\n",
    "    elif mode == 'dist':\n",
    "        weights = list(map(lambda x: x[1], set_preds[start][start + step]))\n",
    "    elif mode == 'mix':\n",
    "        weights = list(map(lambda x: x[1] * x[2], set_preds[start][start + step]))\n",
    "\n",
    "    return pred, preds, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGF1jWZxWlH7"
   },
   "outputs": [],
   "source": [
    "def plot_hist_for_fixed_point(start_point, step, set_preds, y_limit=30):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    modes = ['simple', 'q-value', 'dist', 'mix']\n",
    "    for i, mode in enumerate(modes):\n",
    "        ax = fig.add_subplot(2, 2, i + 1)\n",
    "        pred, preds, weights = get_weights(start_point, step, mode, set_preds)\n",
    "\n",
    "        vals = ax.hist(preds, weights=weights, bins=100, range=(0, 1), label='preds')\n",
    "                    \n",
    "        ax.plot([pred for i in range(2)], [0, y_limit], c='green', label='simple_pred')\n",
    "        ax.plot([x_test[start_point + step] for i in range(2)], [0, y_limit], c='red', \n",
    "                label='real')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.set_title('Mode: ' + mode  + ' || Start:' + str(start_point) + ' || Step ahead:' + str(step))\n",
    "        ax.set_ylim(0, y_limit)\n",
    "        \n",
    "        fig.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVxn6Rx-qAd2"
   },
   "outputs": [],
   "source": [
    "def get_points(step, mae_threshold, predictions):\n",
    "    good_points = []\n",
    "    bad_points = []\n",
    "    for start_point, preds in predictions.items():\n",
    "        if preds[start_point + step]:\n",
    "            mae = abs(x_test[start_point + step] - preds[start_point + step])\n",
    "            if mae > mae_threshold:\n",
    "                bad_points.append(start_point)\n",
    "            else:\n",
    "                good_points.append(start_point)\n",
    "    return good_points, bad_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UDN0i6QcgKs"
   },
   "source": [
    "## mode weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuAYCvnXZfUy"
   },
   "outputs": [],
   "source": [
    "def get_weights(start, step, mode, set_predictions):\n",
    "    return get_weights_with_preds(set_predictions[start][start + step], mode)\n",
    "\n",
    "def get_weights_with_preds(set_preds, mode):\n",
    "    preds = list(map(lambda x: x[0], set_preds))\n",
    "    pred = simple_aggr(set_preds)\n",
    "\n",
    "    if mode == 'simple':\n",
    "        weights = np.ones(len(preds))\n",
    "    elif mode == 'q-value':\n",
    "        pred = aggr_q(set_preds)\n",
    "        weights = list(map(lambda x: x[2], set_preds))\n",
    "    elif mode == 'dist':\n",
    "        pred = aggr_d(set_preds)\n",
    "        weights = list(map(lambda x: x[1], set_preds))\n",
    "    elif mode == 'mix':\n",
    "        pred = aggr_mix(set_preds)\n",
    "        weights = list(map(lambda x: x[1] * x[2], set_preds))\n",
    "\n",
    "    return pred, preds, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqQQtSDdlNM1"
   },
   "source": [
    "## bad points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s83u2moslPfH"
   },
   "outputs": [],
   "source": [
    "def find_bad_points(demon):\n",
    "    good_points = []\n",
    "    bad_points = []\n",
    "    labels = []\n",
    "\n",
    "    for start_point in range(0, PTS):\n",
    "        for step in range(1, STEPS + 1):\n",
    "            if demon.get_predictions()[start_point][start_point + step]:\n",
    "                good_points.append((start_point, step))\n",
    "            else:\n",
    "                bad_points.append((start_point, step))\n",
    "\n",
    "    return good_points, bad_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AN22mZgUlbEo"
   },
   "source": [
    "## statistic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZo73w07lewS"
   },
   "outputs": [],
   "source": [
    "def convert_features_to_percent(good, bad):\n",
    "    features = list(good) + list(bad)\n",
    "    avg = np.mean(features)\n",
    "    return 100 * (good / avg), 100 * (bad / avg)\n",
    "\n",
    "\n",
    "def get_avg_with_alpha(stat, alpha=1.0):\n",
    "    good_features, good_labels, bad_features, bad_labels = get_features_by_stat(stat)\n",
    "    features = list(good_features) + list(bad_features)\n",
    "\n",
    "    return np.mean(features) * alpha \n",
    "\n",
    "def get_features_by_stat(stat):\n",
    "    good_features = []\n",
    "    bad_features = []\n",
    "    \n",
    "    good_labels = []\n",
    "    bad_labels = []\n",
    "\n",
    "    for start, step in good_points:    \n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))    \n",
    "        feature = stat.apply(preds, hist_vals)\n",
    "        good_features.append(feature)\n",
    "        good_labels.append(1)\n",
    "    \n",
    "    for start, step in bad_points:\n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))    \n",
    "        feature = stat.apply(preds, hist_vals)\n",
    "        bad_features.append(feature)\n",
    "        bad_labels.append(0)\n",
    "\n",
    "    return good_features, good_labels, bad_features, bad_labels\n",
    "\n",
    "def visualize_stats(stat, bins=None, thr=None):\n",
    "    good_features, good_labels, bad_features, bad_labels = get_features_by_stat(stat)\n",
    "    \n",
    "    good_bad_ratio = int(round(len(bad_points) / len(good_points)))\n",
    "    good_weights = [good_bad_ratio for _ in range(len(good_features))]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 4))\n",
    "\n",
    "    ax1.set_title(\"Real \" + stat.label() + \" values\")\n",
    "    ret1 = ax1.hist(good_features, bins=bins, weights=good_weights, label='good', color='orange')\n",
    "    ret2 = ax1.hist(bad_features, bins=bins, alpha=0.4, label='bad', color='blue')\n",
    "    if thr == 0:\n",
    "        mean = np.mean(np.append(good_features, bad_features))\n",
    "        max_val = max(np.append(ret1[0] , ret2[0]))\n",
    "        ax1.plot([mean, mean], [0, max_val], label='threshold', color='red')\n",
    "    if thr:\n",
    "        mean = np.mean(np.append(good_features, bad_features))\n",
    "        thr_1 = mean + thr * mean\n",
    "        max_val = max(np.append(ret1[0] , ret2[0]))\n",
    "        ax1.plot([mean, mean], [0, max_val], label='mean', color='green')\n",
    "        ax1.plot([thr_1, thr_1], [0, max_val], label='threshold', color='red')\n",
    "    ax1.legend()\n",
    "\n",
    "    good_percent_features, bad_percent_features = convert_features_to_percent(good_features, bad_features)\n",
    "\n",
    "    ax2.set_title(stat.label() + \" values converted percent of AVG\")\n",
    "    ret1 = ax2.hist(good_percent_features, bins=bins, weights=good_weights, label='good', color='orange')\n",
    "    ret2 = ax2.hist(bad_percent_features, bins=bins, alpha=0.4, label='bad', color='blue')\n",
    "    if thr == 0:\n",
    "        mean = np.mean(np.append(good_percent_features, bad_percent_features))\n",
    "        max_val = max(np.append(ret1[0] , ret2[0]))\n",
    "        ax2.plot([mean, mean], [0, max_val], label='threshold', color='red')\n",
    "    if thr:\n",
    "        mean = np.mean(np.append(good_percent_features, bad_percent_features))\n",
    "        thr_2 = mean + thr * mean\n",
    "        max_val = max(np.append(ret1[0] , ret2[0]))\n",
    "        ax2.plot([mean, mean], [0, max_val], label='mean', color='green')\n",
    "        ax2.plot([thr_2, thr_2], [0, max_val], label='threshold', color='red')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if thr == 0:\n",
    "        return  np.mean(np.append(good_features, bad_features))\n",
    "        \n",
    "    if thr:\n",
    "        return thr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1qZ_Ix5suFF"
   },
   "source": [
    "## correlation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oguPGT82s1FJ"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def visualize_correlation(stats):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "        \n",
    "    data = {stat.label() : [] for stat in stats}\n",
    "    data['label'] = []\n",
    "\n",
    "    for start, step in good_points:\n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))  \n",
    "\n",
    "        for stat in stats:\n",
    "            data[stat.label()].append(stat.apply(preds, hist_vals))\n",
    "        data['label'].append(1)\n",
    "\n",
    "    for start, step in bad_points: \n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))    \n",
    "\n",
    "        for stat in stats:\n",
    "            data[stat.label()].append(stat.apply(preds, hist_vals))\n",
    "        data['label'].append(0)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=data.keys())\n",
    "    corrMatrix = df.corr()\n",
    "\n",
    "    sns.heatmap(corrMatrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su3r-uIxZVaj"
   },
   "source": [
    "## bad points coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvBM964xZafL"
   },
   "outputs": [],
   "source": [
    "def check_bad_points_coverage(demon):\n",
    "    ideal_coverage = 0\n",
    "    demon_coverage = 0\n",
    "\n",
    "    for start_point, step in bad_points:\n",
    "        if not Ideal_deamon.predictions[start_point][start_point + step]:\n",
    "            ideal_coverage += 1\n",
    "        if not demon.predictions[start_point][start_point + step]:\n",
    "            demon_coverage += 1\n",
    "\n",
    "    print(demon.label + \" coverage\", str(int(100 * demon_coverage / len(bad_points))) + \"%\", sep=' ')        \n",
    "    print(\"Ideal coverage\", str(int(100 * ideal_coverage / len(bad_points)))  + \"%\", sep=' ')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfsIC8Nt4EVN"
   },
   "source": [
    "## plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkiSBDHP4Kmb"
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix(demon_1, demon_2):\n",
    "    points = []\n",
    "\n",
    "    for start_point in range(0, PTS):\n",
    "        for step in range(1, STEPS + 1):\n",
    "            label_1 = 1 if demon_1[0].get_predictions()[start_point][start_point + step] else 0\n",
    "            label_2 = 1 if demon_2[0].get_predictions()[start_point][start_point + step] else 0\n",
    "            points.append([start_point, step, label_1, label_2])\n",
    "    df = pd.DataFrame(points, columns=['start_point', 'step', demon_1[1], demon_2[1]])\n",
    "    conf_mat = confusion_matrix(df[demon_2[1]], df[demon_1[1]])\n",
    "\n",
    "    print(\"F1-score: \", f1_score(df[demon_2[1]], df[demon_1[1]]))\n",
    "\n",
    "    conf_mat = np.array(conf_mat) / np.sum(conf_mat)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.axes()\n",
    "    sn.heatmap(conf_mat, annot=True, ax=ax)\n",
    "    ax.set_title('Confusion matrix')\n",
    "    ax.set_xlabel(demon_1[1])\n",
    "    ax.set_ylabel(demon_2[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kdXIVMLVQXt"
   },
   "source": [
    "## get values via ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxAzryBBVPsc"
   },
   "outputs": [],
   "source": [
    "def get_values(raw_vals, ind=0):\n",
    "    return list(map(lambda x: x[ind], raw_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uRjlI7zvzud"
   },
   "source": [
    "## get metrics for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZ3x-O-Dv3Wd"
   },
   "outputs": [],
   "source": [
    "def find_params_for_clustering(clst, par_1_set, par_2_set):\n",
    "    silhouette = []\n",
    "    davies_bouldin = []\n",
    "    \n",
    "    for point in range(PTS):\n",
    "        for step in range(1, STEPS + 1):\n",
    "            raw_values = Simple_deamon_mix_val.get_set_predictions()[point][point + step]\n",
    "            if isinstance(clst, WishartClusterization):\n",
    "                values = np.array(np.unique(get_values(raw_values)))\n",
    "            else:\n",
    "                values = np.array(get_values(raw_values))\n",
    "            clusters = clst.fit(values.reshape(-1, 1))\n",
    "\n",
    "            if len(np.unique(clusters.labels_)) > 1:\n",
    "                silhouette.append(silhouette_score(values.reshape(-1, 1), clusters.labels_))\n",
    "                davies_bouldin.append(davies_bouldin_score(values.reshape(-1, 1), clusters.labels_))\n",
    "\n",
    "    return (np.mean(silhouette), np.mean(davies_bouldin))\n",
    "\n",
    "def get_cluster_metrics(par_1_set, par_2_set, clastering='DBSCAN'):\n",
    "    result = {}\n",
    "\n",
    "    for par_1 in par_1_set:\n",
    "            for par_2 in par_2_set:\n",
    "                if clastering == 'DBSCAN':\n",
    "                    clst = DBSCAN(eps=par_1, min_samples=par_2)\n",
    "                else:\n",
    "                    clst = WishartClusterization(k=par_1, h=par_2)\n",
    "                metrics = find_params_for_clustering(clst, par_1_set, par_2_set)\n",
    "                result[str(par_1) + ' ' + str(par_2)] = metrics\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHa54VfgcHNs"
   },
   "source": [
    "# 2 Initial research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwieGYT6cXsj"
   },
   "source": [
    "## generate lorenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh0V3t0dHIOO"
   },
   "outputs": [],
   "source": [
    "xs, _, _ = Lorentz().generate(0.1, 100000)\n",
    "xs = (xs - xs.min()) / (xs.max() - xs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbm4Sd3KuGUk"
   },
   "outputs": [],
   "source": [
    "x_train = xs[train_start:train_end]\n",
    "x_val = xs[val_start:val_end]\n",
    "x_test = xs[test_start:test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_B69NVSK1gC"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(xs[:1000])\n",
    "plt.xticks([i for i in range(0, 1000, 50)])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXOeQtKAMF6W"
   },
   "source": [
    "## generate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WR_e_sJIw1pl"
   },
   "outputs": [],
   "source": [
    "def generate_patterns():\n",
    "    patterns1 = generate_subsequences(WINDOW_MIN - 1, N - 1, short=True)\n",
    "    patterns2 = generate_subsequences(WINDOW - 1, N - 1)\n",
    "    patterns3 = make_blobs.random.choices(patterns2[300:], k=35)\n",
    "    \n",
    "    return patterns1 + patterns3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Dl7ELumAMF64"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_blobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10139/2965967115.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_trains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_subseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWINDOW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10139/1402781692.py\u001b[0m in \u001b[0;36mgenerate_patterns\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpatterns1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_subsequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW_MIN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpatterns2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_subsequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpatterns3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpatterns1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpatterns3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_blobs' is not defined"
     ]
    }
   ],
   "source": [
    "x_trains = {}\n",
    "patterns = generate_patterns()\n",
    "\n",
    "for pattern in patterns:\n",
    "    key = str_subseq(pattern + (WINDOW - 1,))\n",
    "    \n",
    "    x_trains[key] = generate_sample(x_train, WINDOW, pattern, put_none=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaHq2HJrMvJR"
   },
   "source": [
    "## clusterize train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w86M2s-10JAO"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "centers = generate_centers(x_trains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTUnDoil3tBz"
   },
   "source": [
    "## demons approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvSYRYVUT_S7"
   },
   "source": [
    "### Simple deamon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3on9tf1T-pP"
   },
   "outputs": [],
   "source": [
    "class SimpleDeamon(object):\n",
    "    def __init__(self, mode='simple'):\n",
    "        self.mode = mode\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "\n",
    "        self.predicted = False\n",
    "        \n",
    "    @property\n",
    "    def label(self):\n",
    "        return 'Simple model of demon with ' + self.mode + ' mode'\n",
    "\n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "\n",
    "        if self.mode == 'simple':\n",
    "            pred = simple_aggr(preds)\n",
    "        elif self.mode == 'd_weighted':\n",
    "            pred = aggr_d(preds)\n",
    "        elif self.mode == 'q_weighted':\n",
    "            pred = aggr_q(preds)\n",
    "        elif self.mode == 'mix':\n",
    "            pred = aggr_mix(preds)\n",
    "\n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "        return self.set_predictions\n",
    "\n",
    "    def is_predicted(self):\n",
    "        return self.predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj9SRUrf33sa"
   },
   "source": [
    "### Ideal approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U6p4jLk33FF"
   },
   "outputs": [],
   "source": [
    "class IdealDeamon(object):\n",
    "    def __init__(self, eps=0.05, mode='simple', real_vals=x_test):\n",
    "        self.eps = eps\n",
    "        self.mode = mode \n",
    "        self.real_vals=real_vals\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        \n",
    "    @property\n",
    "    def label(self):\n",
    "        return 'Ideal model of demon'\n",
    "\n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "        pred, _, _ = get_weights(start_point, step, self.mode, self.set_predictions)\n",
    "        if not pred or abs(pred - self.real_vals[start_point + step]) > self.eps:\n",
    "            pred = None\n",
    "\n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_predictions(self):\n",
    "       return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "       return self.set_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN_l3Nvr44Sl"
   },
   "source": [
    "### Difference between min max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y4o6pqr4zMF"
   },
   "outputs": [],
   "source": [
    "class MinMaxDeamon(object):\n",
    "    def __init__(self, eps, aggr_func=simple_aggr):\n",
    "        self.eps = eps\n",
    "        self.aggr_func = aggr_func\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        \n",
    "    @property\n",
    "    def label(self):\n",
    "        return 'Set difference between min max ' + str(self.eps)\n",
    "    \n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "        if not preds:\n",
    "            pred = None\n",
    "        else:\n",
    "            sorted_preds = sorted(preds, key=lambda pred: pred[0], reverse=True)\n",
    "            if abs(sorted_preds[0][0] - sorted_preds[-1][0]) < self.eps:\n",
    "                pred = self.aggr_func(preds)\n",
    "            else:\n",
    "                pred = None\n",
    "        \n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred \n",
    "    \n",
    "    def get_predictions(self):\n",
    "       return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "       return self.set_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccp7N0iaMF7q"
   },
   "source": [
    "## generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKnmo7kWfZtR"
   },
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEq77cFLbR7x"
   },
   "outputs": [],
   "source": [
    "Simple_deamon_val = SimpleDeamon(mode='simple')\n",
    "Ideal_deamon_val = IdealDeamon(real_vals=x_val)\n",
    "\n",
    "deamons = [\n",
    "           Simple_deamon_val,\n",
    "           Ideal_deamon_val\n",
    "]\n",
    "\n",
    "for deamon in deamons:\n",
    "    generate_predictions(centers, deamon=deamon, real_mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GlJQ080fcZB"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GaqwufAAnpF"
   },
   "outputs": [],
   "source": [
    "Simple_deamon_test = SimpleDeamon(mode='simple')\n",
    "Ideal_deamon_test = IdealDeamon()\n",
    "\n",
    "deamons = [\n",
    "           Simple_deamon_test,\n",
    "           Ideal_deamon_test,\n",
    "]\n",
    "\n",
    "for deamon in deamons:\n",
    "    generate_predictions(centers, deamon=deamon, return_set_pred=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfriLoCFfq_S"
   },
   "source": [
    "## visualize metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dqYwNXNf0Mq"
   },
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpUNrtJX_nxN"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                 (Simple_deamon_val, 'Simple avg')], \n",
    "                20,\n",
    "                real_vals=x_val\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtfm6uZ18Ans"
   },
   "outputs": [],
   "source": [
    "deamons = [\n",
    "           (Simple_deamon_val, \"Simple avg\"),\n",
    "           (Ideal_deamon_val, \"Ideal\")\n",
    "]\n",
    "\n",
    "get_metrics(deamons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GMtfrv5f21x"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uovjVYmIf6Aj"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                 (Simple_deamon_test, 'Simple avg')], \n",
    "                9\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNmUpkvOgCzS"
   },
   "outputs": [],
   "source": [
    "deamons = [\n",
    "           (Simple_deamon_test, \"Simple avg\"),\n",
    "           (Ideal_deamon_test, \"Ideal\")\n",
    "]\n",
    "\n",
    "get_metrics(deamons, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlhhvKjChqWJ"
   },
   "source": [
    "## play with h clusterizaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28DfUkY17TS-"
   },
   "outputs": [],
   "source": [
    "h_set = [0.04, 1]\n",
    "\n",
    "centers_set = []\n",
    "for h in h_set:\n",
    "    centers_set.append(generate_centers(x_trains, WISHART_H=h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHx2UnIf75MO"
   },
   "outputs": [],
   "source": [
    "demons_set = []\n",
    "for h in h_set:\n",
    "    demons_set.append(SimpleDeamon(mode='simple'))\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    generate_predictions(centers_set[i], deamon=demon, real_mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFf3qGmf8ZZC"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    demons.append((demon, str(h_set[i])))\n",
    "\n",
    "demons.append((Simple_deamon_val, \"0.2\"))\n",
    "demons.append((Ideal_deamon_val, \"Ideal approx\"))\n",
    "\n",
    "get_metrics(demons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2H5wLygiGBr"
   },
   "source": [
    "## play with q weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXZ6gZs-HodS"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Q_VALUE\")\n",
    "\n",
    "q_set = [0.96, 0.98, 0.99]\n",
    "\n",
    "for q in q_set:\n",
    "    plt.plot([q**i for i in range(0, 50)], label=str(q))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1PDJTckKSq6"
   },
   "outputs": [],
   "source": [
    "demons_set = []\n",
    "for q in q_set:\n",
    "    demons_set.append(SimpleDeamon(mode='q_weighted'))\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    generate_predictions(centers, deamon=demon, real_mode='val', Q_VALUE=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1KIcxUXLxHD"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    demons.append((demon, str(q_set[i])))\n",
    "\n",
    "demons.append((Simple_deamon_val, \"Simple avg\"))\n",
    "demons.append((Ideal_deamon_val, \"Ideal\"))\n",
    "\n",
    "get_metrics(demons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8tmcy6eRG96"
   },
   "source": [
    "## play with min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLhZdgklRG-A"
   },
   "outputs": [],
   "source": [
    "min_max_set = [0.05, 0.2, 0.5]\n",
    "\n",
    "demons_set = []\n",
    "for min_max in min_max_set:\n",
    "    demons_set.append(MinMaxDeamon(min_max))\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    generate_predictions(centers, deamon=demon, real_mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdxRqPmoRG-C"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "for i, demon in enumerate(demons_set):\n",
    "    demons.append((demon, str(min_max_set[i])))\n",
    "\n",
    "demons.append((Simple_deamon_val, \"Simple demon\"))\n",
    "demons.append((Ideal_deamon_val, \"Ideal approx\"))\n",
    "\n",
    "get_metrics(demons, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJnJyltShUp8"
   },
   "source": [
    "## play with modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KIs_kX9hYuf"
   },
   "outputs": [],
   "source": [
    "Simple_deamon_d_val = SimpleDeamon(mode='d_weighted')\n",
    "Simple_deamon_q_val = SimpleDeamon(mode='q_weighted')\n",
    "Simple_deamon_mix_val = SimpleDeamon(mode='mix')\n",
    "\n",
    "demons_set = [\n",
    "           Simple_deamon_d_val,\n",
    "           Simple_deamon_q_val,\n",
    "           Simple_deamon_mix_val\n",
    "]\n",
    "\n",
    "for demon in demons_set:\n",
    "    generate_predictions(centers, deamon=demon, real_mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFEyTWriSb63"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "demons.append((Ideal_deamon_val, \"Ideal\"))\n",
    "demons.append((Simple_deamon_val, \"Simple avg\"))\n",
    "demons.append((Simple_deamon_d_val, \"d-avg\"))\n",
    "demons.append((Simple_deamon_q_val, \"q-avg\"))\n",
    "demons.append((Simple_deamon_mix_val, \"mix-avg\"))\n",
    "#demons.append((MinMax_deamon, \"min max\"))\n",
    "\n",
    "get_metrics(demons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB3yoRDYGuoC"
   },
   "source": [
    "### mix on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wQLXat2Yc1H"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "demons.append((Ideal_deamon_val, \"Ideal\"))\n",
    "demons.append((Simple_deamon_val, \"Simple avg\"))\n",
    "demons.append((Simple_deamon_mix_val, \"Mix avg\"))\n",
    "#demons.append((MinMax_deamon, \"min max\"))\n",
    "\n",
    "get_metrics(demons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCALn9_DGyXJ"
   },
   "source": [
    "### mix on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAeCMsLu_-cn"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "demons.append((Ideal_deamon_test, \"Ideal\"))\n",
    "demons.append((Simple_deamon_test, \"Simple avg\"))\n",
    "demons.append((Simple_deamon_mix_test, \"Mix avg\"))\n",
    "#demons.append((MinMax_deamon, \"min max\"))\n",
    "\n",
    "get_metrics(demons, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWZOR1ZlQPZ9"
   },
   "source": [
    "# 3 Distribution experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwKcRAVI-bdg"
   },
   "source": [
    "## Simple and ideal mix-mode on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfDh_Wa0-ga7"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "demons.append((Ideal_deamon_mix_val, \"Ideal mix-avg\"))\n",
    "demons.append((Simple_deamon_mix_val, \"Mix avg\"))\n",
    "#demons.append((MinMax_deamon, \"min max\"))\n",
    "\n",
    "get_metrics(demons, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRcZusLwCVEG"
   },
   "source": [
    "\n",
    "## find bad points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsHKnkVhKrXT"
   },
   "outputs": [],
   "source": [
    "good_points, bad_points = find_bad_points(Ideal_deamon_mix_val) \n",
    "\n",
    "good_bad_ratio = int(round(len(bad_points) / len(good_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbVWw7UyKuOu"
   },
   "outputs": [],
   "source": [
    "print(\"good points count\", len(good_points))\n",
    "print(\"bad points count\", len(bad_points))\n",
    "\n",
    "print(\"bad/good point ratio\", good_bad_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlD9zFWDEQZ5"
   },
   "source": [
    "### Simple mix val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xc4Vw4PjKzHX"
   },
   "outputs": [],
   "source": [
    "bad = bad_points[2174]\n",
    "print(\"example of bad point\", bad)\n",
    "\n",
    "visualize_point([\n",
    "                (Simple_deamon_mix_val, 'Mix avg')], \n",
    "                bad[0],\n",
    "                real_vals=x_val,\n",
    "                highlight_point=bad[1]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iyjco6wgETGL"
   },
   "source": [
    "### Ideal mix val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iz84Y7VzD6Eb"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                (Ideal_deamon_mix_val, 'Ideal avg')], \n",
    "                bad[0],\n",
    "                real_vals=x_val\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laWP6flWUy_R"
   },
   "source": [
    "## try statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEkSI_KmUbgT"
   },
   "source": [
    "### Mode count \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7A23qaQmMJ2"
   },
   "outputs": [],
   "source": [
    "class Multimode_Stat(object):\n",
    "    def __init__(self, par=0.2):\n",
    "        self.par = par \n",
    "    \n",
    "    def label(self):\n",
    "        return \"Multimode, par=\" + str(self.par)\n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        mode_num = max(hist_vals[0])\n",
    "        return len(list(filter(lambda val: val >= mode_num * self.par, hist_vals[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ut5fB9lULQ2A"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Multimode_Stat(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l--eoXEQCYiF"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Multimode_Stat(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eupFCrjql1_2"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Multimode_Stat(0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WHb5hBzVOg4"
   },
   "source": [
    "### Difference between percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_wAePaPFsFX"
   },
   "outputs": [],
   "source": [
    "class PercentDiff_Stat(object):\n",
    "    def __init__(self, par_left=0, par_right=100):\n",
    "        self.par_left = par_left\n",
    "        self.par_right = par_right \n",
    "    \n",
    "    def label(self):\n",
    "        return \"Diff \" + str(self.par_right) + \" and \" +  str(self.par_left) + \" perc\"\n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        right_border = np.percentile(preds, self.par_right)\n",
    "        left_border = np.percentile(preds, self.par_left)\n",
    "        return abs(right_border - left_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncZmf3hwVinj"
   },
   "outputs": [],
   "source": [
    "visualize_stats(PercentDiff_Stat(par_left=0, par_right=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBfMweWgmRIc"
   },
   "outputs": [],
   "source": [
    "visualize_stats(PercentDiff_Stat(par_left=20, par_right=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-DXvMK_mV4z"
   },
   "outputs": [],
   "source": [
    "visualize_stats(PercentDiff_Stat(par_left=40, par_right=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwsWIiAQmav0"
   },
   "outputs": [],
   "source": [
    "visualize_stats(PercentDiff_Stat(par_left=10, par_right=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBI_MF6l_Y4p"
   },
   "source": [
    "### Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyDUaCU-_Y4r"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "\n",
    "def weighted_mom(values, weights, par):\n",
    "    m = np.average(values, weights=weights)\n",
    "    var = np.average((values - m)**par, weights=weights)\n",
    "    return var * 1000\n",
    "\n",
    "class Moment_Stat(object):\n",
    "    def __init__(self, par=3):\n",
    "        self.par = par\n",
    "    \n",
    "    def label(self):\n",
    "        return str(self.par) + \" moment\" \n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        probs = hist_vals[0] / sum(hist_vals[0])\n",
    "        values = hist_vals[1]\n",
    "\n",
    "        return weighted_mom(values[1:], probs, self.par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm3D7UQ9_Y4u"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Moment_Stat(par=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMDPqkEcm0ob"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Moment_Stat(par=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUOuOYPtm2lW"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Moment_Stat(par=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh5SGqXq_1tA"
   },
   "source": [
    "### Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNt_OeDi_1tC"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "class Entropy(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def label(self):\n",
    "        return \"Entropy\"\n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        probs = hist_vals[0] / sum(hist_vals[0])\n",
    "        return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1npe-ddq_1tG"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Entropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCNEwpiiZsGY"
   },
   "source": [
    "### Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bhGrceAZqtq"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "\n",
    "class Kurtosis_Stat(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def label(self):\n",
    "        return \"Kurtosis\" \n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        return kurtosis(hist_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg0LVp6BZ0p_"
   },
   "outputs": [],
   "source": [
    "visualize_stats(Kurtosis_Stat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-wp9ovYgWml"
   },
   "source": [
    "## correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sz0lbhLcgf_-"
   },
   "outputs": [],
   "source": [
    "stats = [\n",
    "         Multimode_Stat(par=0.2),\n",
    "         Multimode_Stat(par=0.4),\n",
    "         Multimode_Stat(par=0.6),\n",
    "         Multimode_Stat(par=0.8),\n",
    "         PercentDiff_Stat(par_left=0, par_right=100),\n",
    "         PercentDiff_Stat(par_left=20, par_right=80),\n",
    "         PercentDiff_Stat(par_left=40, par_right=60),\n",
    "         Moment_Stat(par=2),\n",
    "         Moment_Stat(par=3),\n",
    "         Moment_Stat(par=4),\n",
    "         Entropy(),\n",
    "         Kurtosis_Stat()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpSSiBpeLyWh"
   },
   "outputs": [],
   "source": [
    "visualize_correlation(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmyC30PBI_AX"
   },
   "source": [
    "## the best stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5eJS9DAI-ca"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(Entropy(), thr=-0.1)\n",
    "ent_thr_1 = (-0.1, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MolgK3zWJot4"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(Entropy(), thr=-0.05)\n",
    "ent_thr_2 = (-0.05, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTC_u2UTKIz8"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(Entropy(), thr=0)\n",
    "ent_thr_3 = (0, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j4q4xSBJrxF"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(Entropy(), thr=0.05)\n",
    "ent_thr_4 = (0.05, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F39ejAKilsYo"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(Entropy(), thr=0.1)\n",
    "ent_thr_5 = (0.1, thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ra9HtxiWgy5"
   },
   "source": [
    "# 4 Clustering experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBQJbt9rYhIW"
   },
   "source": [
    "## take a look on points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33ftxdYtWlLk"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'Mix avg')\n",
    "                ], \n",
    "                17,\n",
    "                real_vals=x_val,\n",
    "                plot_all_points=[i for i in range(1, STEPS +1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Amq6F5XoPc-W"
   },
   "source": [
    "## find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlqTRSRW4dYg"
   },
   "outputs": [],
   "source": [
    "eps_dbscan = [0.001, 0.003, 0.005, 0.007, 0.009, 0.01]\n",
    "min_samples_dbscan =  [3, 4, 5, 6, 8]\n",
    "\n",
    "result_dbscan = get_cluster_metrics(eps_dbscan, min_samples_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJs6ymAk7vmB"
   },
   "outputs": [],
   "source": [
    "k_wishart = [3, 5, 8, 11, 13]\n",
    "h_wishart = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "result_wishart = get_cluster_metrics(k_wishart, h_wishart, clastering='Wishart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6GIGrYDFtDp"
   },
   "outputs": [],
   "source": [
    "result_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSzpYo8_Fy2U"
   },
   "outputs": [],
   "source": [
    "result_wishart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2BopTOAHYXS"
   },
   "source": [
    "## try clusters stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf7C1YA9Lh4p"
   },
   "source": [
    "### Clusters amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3CeJeC8-YQQ"
   },
   "outputs": [],
   "source": [
    "class ClustersAmount_stat(object):\n",
    "    def __init__(self, model=DBSCAN(eps=0.01, min_samples=3)):\n",
    "        self.model = model\n",
    "    \n",
    "    def label(self):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            return \"Amount of clusters Wishart\" \n",
    "        return \"Amount of clusters\"\n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            values = np.array(np.unique(preds))\n",
    "            if len(values) == 2:\n",
    "                if abs(values[0] - values[1]) <= 0.001:\n",
    "                    return 1\n",
    "                return 2\n",
    "        else:\n",
    "            values = np.array(preds)\n",
    "        \n",
    "        if len(values) == 1:\n",
    "            return 1\n",
    "\n",
    "        clusters = self.model.fit(values.reshape(-1, 1))\n",
    "        return len(np.unique(clusters.labels_[clusters.labels_ != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn6xDNwQBjET"
   },
   "outputs": [],
   "source": [
    "visualize_stats(ClustersAmount_stat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rANHS5FOyQns"
   },
   "outputs": [],
   "source": [
    "visualize_stats(ClustersAmount_stat(WishartClusterization(3, 0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTrs7hkbLpsX"
   },
   "source": [
    "### Percent of max cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qf65ztWGS7H"
   },
   "outputs": [],
   "source": [
    "class ClustersPerc_stat(object):\n",
    "    def __init__(self, model=DBSCAN(eps=0.01, min_samples=3)):\n",
    "        self.model = model\n",
    "    \n",
    "    def label(self):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            return \"Percent of max cluster Wishart\" \n",
    "        return \"Percent of max cluster\" \n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            values, counts_values = np.unique(preds, return_counts=True)\n",
    "        \n",
    "        else:\n",
    "            counts_values = np.ones(len(preds))\n",
    "            values = np.array(preds)\n",
    "\n",
    "        clusters = self.model.fit(values.reshape(-1, 1))\n",
    "\n",
    "        labels = []\n",
    "        for i in range(len(counts_values)):\n",
    "            if clusters.labels_[i] != -1: \n",
    "                for j in range(int(counts_values[i])):\n",
    "                    labels.append(clusters.labels_[i])\n",
    "\n",
    "        _, counts_clusters = np.unique(labels, return_counts=True)\n",
    "\n",
    "        return 100 * max(counts_clusters) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEIZSU7vGVC6"
   },
   "outputs": [],
   "source": [
    "visualize_stats(ClustersPerc_stat(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ikTm9jTN_3Q"
   },
   "outputs": [],
   "source": [
    "visualize_stats(ClustersPerc_stat(WishartClusterization(3, 0.1)), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEDB2oT_LvSG"
   },
   "source": [
    "### Difference between max and min cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUivZKXXGVOF"
   },
   "outputs": [],
   "source": [
    "class MinMaxClusterDiff_stat(object):\n",
    "    def __init__(self, model=DBSCAN(eps=0.01, min_samples=3)):\n",
    "        self.model = model\n",
    "    \n",
    "    def label(self):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            return \"Min Max cluster diff Wishart\" \n",
    "        return \"Min Max cluster diff\"\n",
    "\n",
    "    def apply(self, preds, hist_vals):\n",
    "        if isinstance(self.model, WishartClusterization):\n",
    "            values, counts_values = np.unique(preds, return_counts=True)\n",
    "        \n",
    "        else:\n",
    "            counts_values = np.ones(len(preds))\n",
    "            values = np.array(preds)\n",
    "\n",
    "        clusters = self.model.fit(values.reshape(-1, 1))\n",
    "\n",
    "        labels = []\n",
    "        for i in range(len(counts_values)):\n",
    "            if clusters.labels_[i] != -1: \n",
    "                for j in range(int(counts_values[i])):\n",
    "                    labels.append(clusters.labels_[i])\n",
    "        \n",
    "        _, counts_clusters = np.unique(labels, return_counts=True)\n",
    "\n",
    "        return 100 * (max(counts_clusters) - min(counts_clusters)) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Idpl2TOdL2ee"
   },
   "outputs": [],
   "source": [
    "visualize_stats(MinMaxClusterDiff_stat(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw034VAS_zdm"
   },
   "outputs": [],
   "source": [
    "visualize_stats(MinMaxClusterDiff_stat(WishartClusterization(3, 0.1)), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVWJ7PsLN40e"
   },
   "source": [
    "## correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYgEK6jdL2o-"
   },
   "outputs": [],
   "source": [
    "stats = [\n",
    "        ClustersAmount_stat(),\n",
    "        ClustersAmount_stat(WishartClusterization(3, 0.1)),\n",
    "        ClustersPerc_stat(),\n",
    "        ClustersPerc_stat(WishartClusterization(3, 0.1)),\n",
    "        MinMaxClusterDiff_stat(),\n",
    "        MinMaxClusterDiff_stat(WishartClusterization(3, 0.1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeAD0t1gO29L"
   },
   "outputs": [],
   "source": [
    "visualize_correlation(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSh9V2YBN5_s"
   },
   "source": [
    "## the best stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRtxJL-33ld4"
   },
   "source": [
    "### Amount of clusters DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ojb-vW60OK-q"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(ClustersAmount_stat(), thr=-0.1)\n",
    "cluster_thr_1 = (-0.1, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d0AdvQOOAfe"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(ClustersAmount_stat(), thr=0)\n",
    "cluster_thr_2 = (0, thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Qn-6EAfPpaC"
   },
   "outputs": [],
   "source": [
    "thr = visualize_stats(ClustersAmount_stat(), thr=0.1)\n",
    "cluster_thr_3 = (0.1, thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjiOpvfN3s6I"
   },
   "source": [
    "### Amount of clusters Wishart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "150F5HJg4Dvo"
   },
   "source": [
    "### Percent of max xluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iu694RFi4IV"
   },
   "source": [
    "# 5 Filter predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML-bLhKCHVdU"
   },
   "source": [
    "## filter demon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UQ7EpdeEumx"
   },
   "outputs": [],
   "source": [
    "class FilterBasedOnStatDemon(object):\n",
    "    def __init__(self, stat, stat_threshold):\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "\n",
    "        self.predicted = False\n",
    "\n",
    "        self.stat = stat\n",
    "        self.stat_threshold = stat_threshold\n",
    "        \n",
    "    @property\n",
    "    def label(self):\n",
    "        return self.stat.label()\n",
    "\n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "\n",
    "        pred, stat_preds, weights = get_weights_with_preds(preds, 'mix')\n",
    "        hist_vals = np.histogram(stat_preds, weights=weights, bins=100, range=(0, 1))  \n",
    "\n",
    "        if stat_preds:\n",
    "            feature = self.stat.apply(stat_preds, hist_vals)\n",
    "\n",
    "            if feature <= self.stat_threshold:\n",
    "                pred = pred\n",
    "            else:\n",
    "                pred = None\n",
    "        else:\n",
    "            pred = None \n",
    "\n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "        return self.set_predictions\n",
    "\n",
    "    def is_predicted(self):\n",
    "        return self.predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppgCAOcwZqTS"
   },
   "source": [
    "## check best stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98I-qz4yUPRo"
   },
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JyGwwzNUSrL"
   },
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVZRJl2MI0Us"
   },
   "outputs": [],
   "source": [
    "thrs = [ent_thr_1, ent_thr_2, ent_thr_3, ent_thr_4, ent_thr_5]\n",
    "demons_ent = []\n",
    "\n",
    "for thr in thrs:\n",
    "    demons_ent.append((FilterBasedOnStatDemon(Entropy(), stat_threshold=thr[1]), str(thr[0])))\n",
    "\n",
    "\n",
    "for demon in demons_ent:\n",
    "    generate_predictions(centers, deamon=demon[0], real_mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqTduFq4KRXu"
   },
   "outputs": [],
   "source": [
    "demons_ent.append((Simple_deamon_mix_val, \"Mix avg\"))\n",
    "demons_ent.append((Ideal_deamon_val, \"Ideal\"))\n",
    "\n",
    "get_metrics(demons_ent, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MeQ3XelRlnl"
   },
   "source": [
    "#### best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MsO1aldRoPE"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ent[0],\n",
    "             demons_ent[-2],\n",
    "             demons_ent[-1]\n",
    "], x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ztNBHlrR1FA"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ent[0][0], 'Entropy filter')\n",
    "ideal = (Ideal_deamon_val, 'ideal')\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vw6Owuz9nFZ"
   },
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYkafCaS9r16"
   },
   "outputs": [],
   "source": [
    "ent_demon = FilterBasedOnStatDemon(Entropy(), stat_threshold=ent_thr_1[1])\n",
    "generate_predictions(centers, deamon=ent_demon)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohpV_nPn97v8"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal'),\n",
    "             (ent_demon, 'entropy filter')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3DGLC9aBrE2"
   },
   "outputs": [],
   "source": [
    "deamon_check = (ent_demon, 'Entropy filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZooNq8XAUWJb"
   },
   "source": [
    "### Cluster amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8QyKK3TRd2n"
   },
   "outputs": [],
   "source": [
    "thrs = [cluster_thr_1, cluster_thr_2, cluster_thr_3]\n",
    "demons_cluster = []\n",
    "\n",
    "for thr in thrs:\n",
    "    demons_cluster.append((FilterBasedOnStatDemon(ClustersAmount_stat(), stat_threshold=thr[1]), str(thr[0])))\n",
    "\n",
    "\n",
    "for demon in demons_cluster:\n",
    "    generate_predictions(centers, deamon=demon[0], real_mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO0LSbMCRjIT"
   },
   "outputs": [],
   "source": [
    "demons_cluster.append((Simple_deamon_mix_val, \"Mix avg\"))\n",
    "demons_cluster.append((Ideal_deamon_val, \"Ideal\"))\n",
    "\n",
    "get_metrics(demons_cluster, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr1Df5I3T8si"
   },
   "source": [
    "### best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq_zwC7DT-PV"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_cluster[2],\n",
    "             demons_cluster[-2],\n",
    "             demons_cluster[-1]\n",
    "], x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkDWGs6FUNJR"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_cluster[0][0], 'Cluster filter')\n",
    "ideal = (Ideal_deamon_val, 'ideal')\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loSij68eQHWm"
   },
   "source": [
    "# 6 ML experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jv9V8lgKWsPH"
   },
   "source": [
    "## make features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-E2TRxFkrXX"
   },
   "source": [
    "### choose stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ox5wfqcVQ8t"
   },
   "outputs": [],
   "source": [
    "stats = [\n",
    "         Multimode_Stat(par=0.2),\n",
    "         PercentDiff_Stat(par_left=20, par_right=80),\n",
    "         Moment_Stat(par=2),\n",
    "         Entropy(),\n",
    "         Kurtosis_Stat(),\n",
    "         ClustersAmount_stat(),\n",
    "         ClustersAmount_stat(WishartClusterization(3, 0.1)),\n",
    "         ClustersPerc_stat(),\n",
    "         ClustersPerc_stat(WishartClusterization(3, 0.1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKttdeIiXp__"
   },
   "outputs": [],
   "source": [
    "visualize_correlation(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCx19ga1iBd_"
   },
   "outputs": [],
   "source": [
    "lin_stats = [\n",
    "              Multimode_Stat(par=0.2),\n",
    "              Moment_Stat(par=2),\n",
    "              ClustersAmount_stat(WishartClusterization(3, 0.1))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtTMsZv5g4hK"
   },
   "outputs": [],
   "source": [
    "all_stats = [\n",
    "             Multimode_Stat(par=0.2),\n",
    "             Moment_Stat(par=2),\n",
    "             PercentDiff_Stat(par_left=20, par_right=80),\n",
    "             Entropy(),\n",
    "             Kurtosis_Stat(),\n",
    "             ClustersAmount_stat()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7obi2x2kuEJ"
   },
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzv29qhMjXap"
   },
   "outputs": [],
   "source": [
    "def get_features_for_clf(stats):\n",
    "    good_features = []\n",
    "    bad_features = []\n",
    "\n",
    "    good_labels = []\n",
    "    bad_labels = []\n",
    "\n",
    "\n",
    "    for start, step in good_points:    \n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))    \n",
    "        cur_feat = []\n",
    "        for stat in stats:\n",
    "            cur_feat.append(stat.apply(preds, hist_vals))\n",
    "        good_features.append(cur_feat)\n",
    "        good_labels.append(1)\n",
    "\n",
    "    for start, step in bad_points:\n",
    "        pred, preds, weights = get_weights(start, step, 'mix', Simple_deamon_mix_val.get_set_predictions())\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1))    \n",
    "        cur_feat = []\n",
    "        for stat in stats:\n",
    "            cur_feat.append(stat.apply(preds, hist_vals))\n",
    "        bad_features.append(cur_feat)\n",
    "        bad_labels.append(0)\n",
    "\n",
    "    return good_features + bad_features, good_labels + bad_labels\n",
    "\n",
    "\n",
    "X_lin, y_lin = get_features_for_clf(lin_stats)\n",
    "\n",
    "X, y = get_features_for_clf(all_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SxSwn60lwzc"
   },
   "source": [
    "### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp4uUfNHlyo3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "X_lin, lin_scaler = scale(X_lin)\n",
    "X, scaler = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOMvCGsAk2GW"
   },
   "source": [
    "### solve imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jdZyIwek8R2"
   },
   "outputs": [],
   "source": [
    "y.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti138MNUk-Of"
   },
   "outputs": [],
   "source": [
    "y.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtmC4x8wkmQx"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def data_balance(X, y):\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    return X_res, y_res\n",
    "\n",
    "X_lin, y_lin = data_balance(X_lin, y_lin)\n",
    "X, y = data_balance(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNX0jVghndHH"
   },
   "source": [
    "### check classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RB1qORB8snJS"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOX6F2VHlTU7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(X_lin, y_lin, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "punuHsppisQg"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_clf(clf, features, labels):\n",
    "    return clf.fit(features, labels)\n",
    "\n",
    "def greed_search(clf, params, X_train, X_test, y_train, y_test):\n",
    "    gs_clf = GridSearchCV(estimator=clf, \n",
    "                          param_grid=params,\n",
    "                          scoring='f1',\n",
    "                          cv=10,\n",
    "                          n_jobs=-1)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    best_clf = gs_clf.best_estimator_\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1-score: \", f1_score(y_test, y_pred))\n",
    "    print(\"Best params: \", gs_clf.best_params_)\n",
    "    return best_clf\n",
    "\n",
    "def check_clf(clf, params, X_train, X_test, y_train, y_test):\n",
    "    print(clf[1])\n",
    "    best_clf = greed_search(clf[0], params, X_train, X_test, y_train, y_test)\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGn6NBlVi_a8"
   },
   "outputs": [],
   "source": [
    "all_params = [\n",
    "              {'C' : [1e-2, 1e-1, 1]},\n",
    "              {'C' : [1e-2, 1e-1, 1, 10],\n",
    "               'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "              {'criterion' : ['gini', 'entropy'],\n",
    "               'max_depth': [None, 2, 4, 6, 8]},\n",
    "              {'n_neighbors' : [3, 5, 7],\n",
    "               'weights' : ['uniform', 'distance']},\n",
    "              {'hidden_layer_sizes' : [(8,),(16,), (32,), (64, 32), \n",
    "                                       (64, 32, 16), (128, 64, 32, 16)],\n",
    "               'activation' : ['logistic']}\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "               (LogisticRegression(), 'logreg'),\n",
    "               (SVC(), 'svm'),\n",
    "               (DecisionTreeClassifier(), 'decision tree'),\n",
    "               (KNeighborsClassifier(), 'knn'),\n",
    "               (MLPClassifier(), 'mlp')\n",
    "]\n",
    "\n",
    "best_classifiers = []\n",
    "\n",
    "for i, clf in enumerate(classifiers):\n",
    "    if clf[1] == 'logreg':\n",
    "        cur_clf = check_clf(clf, all_params[i], X_train_lin, X_test_lin, y_train_lin, y_test_lin)\n",
    "    else:\n",
    "        cur_clf = check_clf(clf, all_params[i], X_train, X_test, y_train, y_test)\n",
    "    best_classifiers.append((cur_clf, clf[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXx7bfw9np55"
   },
   "source": [
    "## Filter demon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgBeHi8hnonU"
   },
   "outputs": [],
   "source": [
    "class MLDemon(object):\n",
    "    def __init__(self, clf, stats, scaler, ensemble=False):\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.clf = clf\n",
    "        self.stats = stats\n",
    "        self.scaler = scaler\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "    @property\n",
    "    def label(self):\n",
    "        return self.stat.label()\n",
    "\n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "        if not preds:\n",
    "            pred = None \n",
    "            self.predictions[start_point].append(pred)\n",
    "            return pred\n",
    "        \n",
    "        pred, preds, weights = get_weights(start_point, step, 'mix', self.set_predictions)\n",
    "        hist_vals = np.histogram(preds, weights=weights, bins=100, range=(0, 1)) \n",
    "\n",
    "        features = []\n",
    "        for stat in self.stats:\n",
    "            features.append(stat.apply(preds, hist_vals))\n",
    "        \n",
    "        features = self.scaler.transform([features])\n",
    "        \n",
    "        if self.ensemble:\n",
    "\n",
    "            votes = [c.predict(features) for c in clf]\n",
    "\n",
    "            if np.mean(votes) <= 0.5:\n",
    "                pred = None \n",
    "                self.predictions[start_point].append(pred)\n",
    "                return pred\n",
    "        else:\n",
    "            if not self.clf.predict(features):\n",
    "                pred = None \n",
    "                self.predictions[start_point].append(pred)\n",
    "                return pred\n",
    "        \n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "        return self.set_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnpUvSu5OcEN"
   },
   "source": [
    "### Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lobQXVCSnzD9"
   },
   "outputs": [],
   "source": [
    "demons_ml = []\n",
    "\n",
    "for clf in best_classifiers:\n",
    "    if clf[1] == 'logreg':\n",
    "        trained_clf = clf[0].fit(X_lin, y_lin)\n",
    "        ml_demon = MLDemon(clf=trained_clf, stats=lin_stats, scaler=lin_scaler)\n",
    "    else:\n",
    "        trained_clf = clf[0].fit(X, y)\n",
    "        ml_demon = MLDemon(clf=trained_clf, stats=all_stats, scaler=scaler)\n",
    "    generate_predictions(centers, deamon=ml_demon, real_mode='test')\n",
    "    demons_ml.append((ml_demon, clf[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7c97_4RLTp2"
   },
   "source": [
    "#### simple models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQL27y0nPMuW"
   },
   "outputs": [],
   "source": [
    "demons_ml.append((Simple_deamon_mix_test, \"Mix avg\"))\n",
    "demons_ml.append((Ideal_deamon_test, \"Ideal\"))\n",
    "\n",
    "get_metrics(demons_ml, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kugz3bdfpDB0"
   },
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s[~np.isnan(s)].min()\n",
    "    return ['color: red' if v else 'color: black' for v in is_max]\n",
    "\n",
    "\n",
    "def error_table_per_step(demons, steps=[1] + [i for i in range(5, 51, 5)]):\n",
    "    mae_res = [[round(get_metrics([demon], x_test, return_values=True, plot=False)[0][0][0][i], 3) if get_metrics([demon], x_test, return_values=True, plot=False)[0][0][0][i] != None else None for i in steps] for demon in demons]\n",
    "    rmse_res = [[round(get_metrics([demon], x_test, return_values=True, plot=False)[1][0][0][i], 3) if get_metrics([demon], x_test, return_values=True, plot=False)[1][0][0][i] != None else None for i in steps] for demon in demons]\n",
    "    non_pred_res = [[int(get_metrics([demon], x_test, return_values=True, plot=False)[2][0][0][i]) for i in steps] for demon in demons]\n",
    "    inds = [demon[1] + ' filter' for demon in demons]\n",
    "\n",
    "    df_mae = pd.DataFrame(data=mae_res, index=inds, columns=steps)\n",
    "    df_mae = df_mae.style.highlight_min()\n",
    "\n",
    "    df_rmse = pd.DataFrame(data=rmse_res, index=inds, columns=steps)\n",
    "    df_rmse = df_rmse.style.highlight_min()\n",
    "\n",
    "    df_non_pred = pd.DataFrame(data=non_pred_res, index=inds, columns=steps)\n",
    "    df_non_pred = df_non_pred.style.highlight_min()\n",
    "    return df_mae, df_rmse, df_non_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HUrBIo5rtwA"
   },
   "outputs": [],
   "source": [
    "df_mae, df_rmse, df_non_pred = error_table_per_step(demons_ml[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML6I71Nifg8x"
   },
   "outputs": [],
   "source": [
    "df_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9a6nS9sfisl"
   },
   "outputs": [],
   "source": [
    "df_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ-_ruA_fka4"
   },
   "outputs": [],
   "source": [
    "df_non_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8aGfmDlLSNU"
   },
   "source": [
    "##### logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EtB6QLaHTae"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[0],\n",
    "             demons_ml[-2],\n",
    "             demons_ml[-1]\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1jdgtp-MwSQ"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ml[0][0], 'logreg filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1qpXoiVjejB"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (demons_ml[0][0], demons_ml[0][1] + ' filter')\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNKV6l7OLZiq"
   },
   "source": [
    "##### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5G0lHXYmLaNh"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[1],\n",
    "             demons_ml[-2],\n",
    "             demons_ml[-1]\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWXbv5BcM5nd"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ml[1][0], 'SVM filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnsBrVnPd82w"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (demons_ml[1][0], demons_ml[1][1] + ' filter')\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLeeLUXZL-hN"
   },
   "source": [
    "##### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M_ozJF9L_AA"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[2],\n",
    "             demons_ml[-2],\n",
    "             demons_ml[-1]\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMIJixsDMoA7"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ml[2][0], 'decision tree filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eifokTzjxGX"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (demons_ml[2][0], demons_ml[2][1] + ' filter')\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5YDAEoGMFcx"
   },
   "source": [
    "##### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLaMXRtLMF3T"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[3],\n",
    "             demons_ml[-2],\n",
    "             demons_ml[-1]\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OipNSWfaNV24"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ml[3][0], 'knn filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BzsKTnRj0MZ"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (demons_ml[3][0], demons_ml[3][1] + ' filter')\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK-69p-MMMj4"
   },
   "source": [
    "##### mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJCxpLE_MMwe"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[4],\n",
    "             demons_ml[-2],\n",
    "             demons_ml[-1]\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxEbv6PENha0"
   },
   "outputs": [],
   "source": [
    "deamon_check = (demons_ml[4][0], 'mlp filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Wlu0vB4j_7F"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (demons_ml[4][0], demons_ml[4][1] + ' filter')\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTNnijk_OXA1"
   },
   "source": [
    "### ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7mfD3A9MQcn"
   },
   "source": [
    "#### ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdmHh9zWJTdf"
   },
   "outputs": [],
   "source": [
    "ensemble_demons = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    if clf[1] == 'knn' or clf[1] == 'mlp':\n",
    "        continue\n",
    "    if clf[1] == 'logreg':\n",
    "        trained_clf = AdaBoostClassifier(base_estimator=clf[0], algorithm='SAMME').fit(X_lin, y_lin)\n",
    "        ml_demon = MLDemon(clf=trained_clf, stats=lin_stats, scaler=lin_scaler)\n",
    "    else:\n",
    "        trained_clf = AdaBoostClassifier(base_estimator=clf[0], algorithm='SAMME').fit(X, y)\n",
    "        ml_demon = MLDemon(clf=trained_clf, stats=all_stats, scaler=scaler)\n",
    "    generate_predictions(centers, deamon=ml_demon, real_mode='test')\n",
    "    ensemble_demons.append((ml_demon, 'ada boost ' + clf[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8l_KA4kMQq2"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             ensemble_demons[0],\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWFS_Aslvx_c"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 ensemble_demons[0]\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZMjkBzoklIE"
   },
   "outputs": [],
   "source": [
    "deamon_check = ensemble_demons[0]\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmG9hSRNkIgV"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             ensemble_demons[1],\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-j9JJ4FalRJp"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 ensemble_demons[1]\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2cztsojktrb"
   },
   "outputs": [],
   "source": [
    "deamon_check = ensemble_demons[1]\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySKT1R__kLUv"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             ensemble_demons[2],\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-Esbs__N5Ta"
   },
   "outputs": [],
   "source": [
    "deamon_check = ensemble_demons[2]\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCFcJ7avMXCf"
   },
   "source": [
    "#### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPIcpAUPN-xc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "classifiers_1 = [\n",
    "               ('logreg', best_classifiers[0][0]),\n",
    "               ('svm', best_classifiers[1][0]),\n",
    "               #('decision tree', DecisionTreeClassifier()),\n",
    "               #('knn', KNeighborsClassifier()),\n",
    "               ('mlp', best_classifiers[4][0])\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(estimators=classifiers_1[1:]).fit(X, y)\n",
    "stacking_demon = MLDemon(clf=clf, stats=all_stats, scaler=scaler)\n",
    "generate_predictions(centers, deamon=stacking_demon, real_mode='test')\n",
    "stacking_demon = (stacking_demon, 'stacking')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9hVo_aKo5Ra"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             stacking_demon,\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtWkYJtFq_s_"
   },
   "outputs": [],
   "source": [
    "deamon_check = stacking_demon\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v1O-Ot0vpiJ"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 stacking_demon\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juyNWG8OMcBj"
   },
   "source": [
    "#### voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DzMRucbMdyL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "classifiers_1 = [\n",
    "               ('logreg', best_classifiers[0][0]),\n",
    "               ('svm', best_classifiers[1][0]),\n",
    "               #('decision tree', DecisionTreeClassifier()),\n",
    "               #('knn', KNeighborsClassifier()),\n",
    "               ('mlp', best_classifiers[4][0])\n",
    "]\n",
    "\n",
    "clf = VotingClassifier(estimators=classifiers_1).fit(X, y)\n",
    "voting_demon = MLDemon(clf=clf, stats=all_stats, scaler=scaler)\n",
    "generate_predictions(centers, deamon=voting_demon, real_mode='test')\n",
    "voting_demon = (voting_demon, 'voting')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4a0iCnjvHup"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             voting_demon,\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n_9_zDZODhy"
   },
   "outputs": [],
   "source": [
    "deamon_check = voting_demon\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Dpj_rEhvdAV"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 voting_demon\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv2y_1xCwFT9"
   },
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5tDiv88v9nj"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier().fit(X, y)\n",
    "random_for_demon = MLDemon(clf=clf, stats=all_stats, scaler=scaler)\n",
    "generate_predictions(centers, deamon=random_for_demon, real_mode='test')\n",
    "random_for_demon = (random_for_demon, 'rnd forest')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9XCrAcVwtdZ"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             random_for_demon,\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YNNVB_gwyFR"
   },
   "outputs": [],
   "source": [
    "deamon_check = random_for_demon\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdWQgDt2zxyH"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 random_for_demon\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSsMa1gSxL28"
   },
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXRpFIwqwfk6"
   },
   "outputs": [],
   "source": [
    "df_mae, df_rmse, df_non_pred = error_table_per_step([demons_ml[0], \n",
    "                                                     demons_ml[1], \n",
    "                                                     demons_ml[-3], \n",
    "                                                     #demons_ml[3], \n",
    "                                                     #demons_ml[4], \n",
    "                                                     ensemble_demons[0],\n",
    "                                                     ensemble_demons[1],\n",
    "                                                     voting_demon,\n",
    "                                                     stacking_demon\n",
    "                                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usaWKVqQxacp"
   },
   "outputs": [],
   "source": [
    "df_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86M1ffj5xcfC"
   },
   "outputs": [],
   "source": [
    "df_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qL4iFAloxeh7"
   },
   "outputs": [],
   "source": [
    "df_non_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Frb0nGE7ry3U"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             demons_ml[0], \n",
    "            demons_ml[1], \n",
    "            demons_ml[-3], \n",
    "            ensemble_demons[0],\n",
    "            ensemble_demons[1],\n",
    "            voting_demon,\n",
    "            stacking_demon,\n",
    "            random_for_demon,\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal')\n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vjE7sLL1kfU"
   },
   "outputs": [],
   "source": [
    "get_metrics([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "             #demons_ml[0], \n",
    "              #demons_ml[1], \n",
    "              demons_ml[-3], \n",
    "              #ensemble_demons[1],\n",
    "              stacking_demon,\n",
    "              #random_for_demon\n",
    "              ], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ta9Mk2aTrSR"
   },
   "source": [
    "# 7 Three points expiriment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Z_YydL_Y_y5"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'Mix avg')\n",
    "                ], \n",
    "                17,\n",
    "                real_vals=x_val,\n",
    "                plot_all_points=[i for i in range(1, STEPS +1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9Dh8S1D4hvT"
   },
   "outputs": [],
   "source": [
    "def get_spread_plot(point, demon):\n",
    "    preds = demon.get_set_predictions()[point]\n",
    "    \n",
    "    spread = []\n",
    "    for step in range(1, STEPS + 1):\n",
    "        values = get_values(preds[point + step])\n",
    "        spread.append(max(values) - min(values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('spread')\n",
    "    plt.plot([i for i in range(1, STEPS + 1)], spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qge8z8mE4np6"
   },
   "outputs": [],
   "source": [
    "get_spread_plot(17, Simple_deamon_mix_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0q78nZ7IeqS"
   },
   "source": [
    "## filter demon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orVH-tGKUXbh"
   },
   "outputs": [],
   "source": [
    "def get_values(raw_points, ind=0):\n",
    "    return list(map(lambda x: x[ind], raw_points))\n",
    "\n",
    "\n",
    "class ThreePointsFilterDemon(object):\n",
    "    def __init__(self, mode='simple', minmax_thr=0, cl_thr=0, cluster_method=None):\n",
    "        self.mode = mode\n",
    "        self.cluster_method = cluster_method\n",
    "        self.minmax_thr = minmax_thr\n",
    "        self.cl_thr = cl_thr\n",
    "\n",
    "        self.minmax_metric = [None]\n",
    "        self.cl_metric = [None]\n",
    "        self.predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        self.set_predictions = {point : [None for i in range(point + 1)] for point in range(PTS)}\n",
    "        \n",
    "        \n",
    "\n",
    "    @property\n",
    "    def label(self):\n",
    "        return 'Three points filter'\n",
    "\n",
    "    def predict(self, start_point, step, preds):\n",
    "        self.set_predictions[start_point].append(preds)\n",
    "        if step == 1:\n",
    "            self.minmax_metric = [None]\n",
    "            self.cl_metric = [None]\n",
    "        \n",
    "        values = np.array(get_values(preds))\n",
    "\n",
    "        if not preds:\n",
    "            pred = None\n",
    "            self.cl_metric.append(None)\n",
    "            self.minmax_metric.append(None)\n",
    "            self.predictions[start_point].append(pred)\n",
    "            return pred\n",
    "        \n",
    "        \n",
    "\n",
    "        if self.cluster_method:\n",
    "            clusters = self.cluster_method.fit(values.reshape(-1, 1))\n",
    "            cur_cl_am = len(np.unique(clusters.labels_))\n",
    "        \n",
    "        cur_minmax_diff = (max(values) - min(values)) * 10\n",
    "\n",
    "        if step >= 3:\n",
    "\n",
    "            if self.minmax_metric[step - 1] and self.minmax_metric[step - 2]:\n",
    "                minmax_diff_1 = cur_minmax_diff - self.minmax_metric[step - 1]\n",
    "                minmax_diff_2 = self.minmax_metric[step - 1] - self.minmax_metric[step - 2]\n",
    "\n",
    "                if self.cluster_method:\n",
    "                    cl_diff_1 = cur_cl_am - self.cl_metric[step - 1]\n",
    "                    cl_diff_2 = self.cl_metric[step - 1] - self.cl_metric[step - 2]\n",
    "\n",
    "                    if minmax_diff_1 >= self.minmax_thr and minmax_diff_2 >= self.minmax_thr and cl_diff_1 >= self.cl_thr and cl_diff_2 >= self.cl_thr:\n",
    "                        pred = None\n",
    "                        self.cl_metric.append(cur_cl_am)\n",
    "                        self.minmax_metric.append(cur_minmax_diff)\n",
    "                        self.predictions[start_point].append(pred)\n",
    "                        return pred\n",
    "                else:\n",
    "                    if minmax_diff_1 >= self.minmax_thr and minmax_diff_2 >= self.minmax_thr:\n",
    "                        pred = None\n",
    "                        self.minmax_metric.append(cur_minmax_diff)\n",
    "                        self.predictions[start_point].append(pred)\n",
    "                        return pred\n",
    "\n",
    "        pred, _, _ = get_weights_with_preds(preds, self.mode)\n",
    "        \n",
    "        if self.cluster_method:\n",
    "            self.cl_metric.append(cur_cl_am)\n",
    "        \n",
    "        self.minmax_metric.append(cur_minmax_diff)\n",
    "        self.predictions[start_point].append(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_predictions(self):\n",
    "       return self.predictions\n",
    "    \n",
    "    def get_set_predictions(self):\n",
    "       return self.set_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Enh6v5URIbuI"
   },
   "source": [
    "## Min max check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmUNk4W5UdPw"
   },
   "outputs": [],
   "source": [
    "three_points_demon = ThreePointsFilterDemon(mode='mix', minmax_thr=0)\n",
    "\n",
    "generate_predictions(centers, deamon=three_points_demon, real_mode='test')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFDytE1_Uoth"
   },
   "outputs": [],
   "source": [
    "demons = []\n",
    "\n",
    "demons.append((three_points_demon, '3 pts filter'))\n",
    "demons.append((Simple_deamon_mix_test, \"Mix avg\"))\n",
    "demons.append((Ideal_deamon_test, \"Ideal\"))\n",
    "\n",
    "get_metrics(demons, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6MtCRGHB_2r"
   },
   "outputs": [],
   "source": [
    "visualize_point([(Simple_deamon_mix_test, 'Mix avg'),\n",
    "                 (three_points_demon, '3 pts filter'),\n",
    "                 ],\n",
    "                93, \n",
    "                real_vals=x_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyCyRPoDdqPn"
   },
   "outputs": [],
   "source": [
    "deamon_check = (three_points_demon, '3 pts filter')\n",
    "ideal = (Ideal_deamon_test, 'ideal')\n",
    "\n",
    "get_confusion_matrix(deamon_check, ideal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N46v2ScBIrfJ"
   },
   "source": [
    "## DBSCAN check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2NgkZwFI8ps"
   },
   "outputs": [],
   "source": [
    "three_points_demons = []\n",
    "\n",
    "dbs = DBSCAN(eps=0.1, min_samples=3)\n",
    "three_points_demons_dbscan = ThreePointsFilterDemon(mode='mix', minmax_thr=0, \n",
    "                                                  cl_thr=0, cluster_method=dbs)\n",
    "\n",
    "generate_predictions(centers, deamon=three_points_demons_dbscan, real_mode='test')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytPmvamM_xf9"
   },
   "outputs": [],
   "source": [
    "get_metrics([(three_points_demons_dbscan, '3 pts fltr with DBSCAN'),\n",
    "             (Simple_deamon_mix_test, \"Mix avg\"),\n",
    "             (Ideal_deamon_test, \"Ideal\")], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR4uVy50Iurh"
   },
   "source": [
    "## Wishart check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdjcZevtdXmI"
   },
   "outputs": [],
   "source": [
    "wishart = WishartClusterization(k=3, h=0.1)\n",
    "three_points_demons_wishart = ThreePointsFilterDemon(mode='mix', minmax_thr=0, \n",
    "                                                  cl_thr=0, cluster_method=wishart)\n",
    "\n",
    "\n",
    "generate_predictions(centers, deamon=three_points_demons_wishart, real_mode='test')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWKbh_I7FtNM"
   },
   "outputs": [],
   "source": [
    "get_metrics([(three_points_demons_wishart, '3 pts wishart'),\n",
    "             (three_points_demons_dbscan, '3 pts DBSCAN'),\n",
    "             (three_points_demon, '3 pts'),\n",
    "             (Simple_deamon_mix_test, \"Mix avg\"),\n",
    "             (Ideal_deamon_test, \"Ideal\")], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61BjvEWK5RPs"
   },
   "source": [
    "# CHECK ALL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWjQtGCx577W"
   },
   "source": [
    "## ML exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A38iWwYA5Qo_"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             #(Simple_deamon_test, 'Simple avg'),\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal'),\n",
    "             voting_demon,\n",
    "             demons_ml[-3],\n",
    "             ensemble_demons[0]\n",
    "             \n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIgH9RtT7sL9"
   },
   "source": [
    "## final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMJHsEu3EbLZ"
   },
   "outputs": [],
   "source": [
    "get_metrics([\n",
    "             #(Simple_deamon_test, 'Simple avg'),\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal'),\n",
    "             voting_demon,\n",
    "             demons_ml[-3],\n",
    "             ensemble_demons[0],\n",
    "             (ent_demon, 'entropy'),\n",
    "             (three_points_demons, \"3 pts filter\")\n",
    "             \n",
    "             \n",
    "], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_QjQdxxoGkR"
   },
   "outputs": [],
   "source": [
    "df_mae, df_rmse, df_non_pred = error_table_per_step([[\n",
    "             #(Simple_deamon_test, 'Simple avg'),\n",
    "             (Simple_deamon_mix_test, 'Mix avg'),\n",
    "             (Ideal_deamon_test, 'Ideal'),\n",
    "             voting_demon,\n",
    "             demons_ml[-3],\n",
    "             ensemble_demons[0],\n",
    "             (ent_demon, 'entropy'),\n",
    "             (three_points_demons, \"3 pts filter\")\n",
    "             \n",
    "             \n",
    "]\n",
    "                                                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAQNiuavTxeU"
   },
   "source": [
    "# 8 Tube expiriment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk78vovJSF0T"
   },
   "outputs": [],
   "source": [
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'mix')\n",
    "                 ],\n",
    "                20,\n",
    "                real_vals=x_val\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gxxnWsgSJXI"
   },
   "outputs": [],
   "source": [
    "def get_nearest_centers(wind, centers):\n",
    "    x_tests_for_point = {}\n",
    "    for pattern in patterns:\n",
    "        \n",
    "        key = str_subseq(pattern + (WINDOW - 1,)) \n",
    "        sample = gen_sample_in_point_with_q(np.concatenate([wind, [(0, 0)]]), \n",
    "                                            WINDOW, pattern, len(wind))\n",
    "        if not sample:\n",
    "            x_tests_for_point[key] = None\n",
    "        else:\n",
    "            x_tests_for_point[key] = sample\n",
    "\n",
    "    chosen_centers = []\n",
    "    for pattern, centers_values in centers.items():\n",
    "        if not x_tests_for_point[pattern]:\n",
    "            continue\n",
    "        vector = np.array(x_tests_for_point[pattern][:-1])[:, 0]\n",
    "        q_values = np.array(x_tests_for_point[pattern][:-1])[:, 1]\n",
    "\n",
    "        for center in centers_values:\n",
    "            dist = euclidean(vector, center[:-1])\n",
    "            if dist < EPS:\n",
    "                weight_d = (EPS - dist) / EPS\n",
    "                weight_q = np.mean(q_values) * Q_VALUE\n",
    "                chosen_centers.append((center, weight_d, weight_q))\n",
    "\n",
    "    last_points = list(map(lambda center: (center[0][-1], center[1], center[2]), \n",
    "                                  chosen_centers))\n",
    "    return last_points\n",
    "\n",
    "def make_step(wind):\n",
    "    nearest_centers = get_nearest_centers(wind, centers)\n",
    "    return nearest_centers\n",
    "\n",
    "def get_values(raw_preds, ind=0):\n",
    "    return list(map(lambda x: x[ind], raw_preds))\n",
    "\n",
    "def is_equal(a, b):\n",
    "    return abs(a - b) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jdp4svDTWpR"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "all_trajectories = []\n",
    "all_res_tubes = []\n",
    "#RAND_CL_AM_VALS = [1, 3, 5]\n",
    "\n",
    "dbs = DBSCAN(eps=0.01, min_samples=3)\n",
    "TUBE_LABEL_LIMIT = 3\n",
    "TUBE_SIZE = 20\n",
    "RAND_CL_AM = 1\n",
    "point = 20\n",
    "\n",
    "\n",
    "\n",
    "for point in trange(20):\n",
    "    wind = list(map(lambda x: (x, 1), xs[train_end + point : val_init + point]))\n",
    "\n",
    "    p = [1]\n",
    "    windows = [wind]\n",
    "    trajectories = [[]]\n",
    "\n",
    "    for step in range(1, 51):\n",
    "        #print(\"STEP:\", step)\n",
    "\n",
    "        new_p = []\n",
    "        new_windows = []\n",
    "        new_trajectories = []\n",
    "        for tube_i in range(len(windows)):\n",
    "            wind = windows[tube_i]\n",
    "        \n",
    "            nearest_centers = make_step(wind)\n",
    "            values = np.array(get_values(nearest_centers))\n",
    "            q_vals = np.array(get_values(nearest_centers, ind=2))\n",
    "\n",
    "            clusters = dbs.fit(values.reshape(-1, 1))\n",
    "            labels, label_vals, counts = np.unique(\n",
    "                clusters.labels_[clusters.labels_ != -1], \n",
    "                return_inverse=True, \n",
    "                return_counts=True\n",
    "            )\n",
    "            probs = counts / len(values)\n",
    "\n",
    "            descending = np.argsort(probs)[::-1]\n",
    "\n",
    "            if len(descending) > RAND_CL_AM:\n",
    "                descending = np.append(descending[0], descending[np.random.choice(np.arange(1, len(descending)), \n",
    "                                                                                  RAND_CL_AM, replace=False)])\n",
    "\n",
    "            label_vals = label_vals[descending]\n",
    "            probs = probs[descending]\n",
    "            labels = labels[descending]\n",
    "          \n",
    "\n",
    "            for i in range(min(TUBE_LABEL_LIMIT, len(labels))):\n",
    "                prediction = np.mean(values[clusters.labels_ == labels[i]])\n",
    "                q_value = np.mean(q_vals[clusters.labels_ == labels[i]])\n",
    "                \n",
    "                new_window = np.concatenate([wind[1:], [(prediction, q_value)]])\n",
    "                \n",
    "                new_p.append(p[tube_i] * probs[i] * 5)\n",
    "                new_windows.append(new_window)\n",
    "                \n",
    "                old_trajectory = list(trajectories[tube_i].copy())\n",
    "                old_trajectory.append(prediction)\n",
    "\n",
    "                new_trajectories.append(old_trajectory)\n",
    "        \n",
    "        descending = np.argsort(new_p)[::-1]\n",
    "        windows = np.array(new_windows)[descending][:TUBE_SIZE]\n",
    "        trajectories = np.array(new_trajectories)[descending][:TUBE_SIZE]\n",
    "        p = np.array(new_p)[descending][:TUBE_SIZE]\n",
    "        \n",
    "    \n",
    "    p_norm = p / np.sum(p)\n",
    "    res_tube = trajectories.T.dot(p_norm)\n",
    "        \n",
    "    \n",
    "    all_trajectories.append(trajectories)\n",
    "    all_res_tubes.append(res_tube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKtKuKIH06MB"
   },
   "source": [
    "## errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01Nihs9LwWLc"
   },
   "outputs": [],
   "source": [
    "mae_res = np.zeros((51,))\n",
    "rmse_res = np.zeros((51,))\n",
    "non_pred_res = np.zeros((51,))\n",
    "\n",
    "for point in range(20):\n",
    "    for step in range(1, STEPS + 1):\n",
    "        cur_val = all_res_tubes[point][step - 1]\n",
    "        if cur_val == None:\n",
    "            non_pred_res[step] += 1\n",
    "        else:\n",
    "            mae_res[step] += abs(x_val[point + step] - cur_val)\n",
    "            rmse_res[step] += (x_val[point + step] - cur_val)**2\n",
    "\n",
    "mae_res /= 20\n",
    "rmse_res = np.sqrt(rmse_res  / 20) \n",
    "non_pred_res /= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MrM19yY0Fx4"
   },
   "outputs": [],
   "source": [
    "mae_all, rmse_all, non_pred_all = get_metrics([\n",
    "             (Simple_deamon_mix_val, 'Simple'),\n",
    "             (Ideal_deamon_val, 'Ideal')],\n",
    "            actual=x_val,\n",
    "            return_values=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVoCMc0701iD"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for er in mae_all:\n",
    "    plt.plot(er[0], label=er[1])\n",
    "\n",
    "plt.plot(mae_res, label='tube')\n",
    "plt.grid()\n",
    "plt.title('MAE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lO4H0ET1o-a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for er in rmse_all:\n",
    "    plt.plot(er[0], label=er[1])\n",
    "\n",
    "plt.plot(rmse_res, label='tube')\n",
    "plt.grid()\n",
    "plt.title('RMSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLeEOBlW-IEg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for er in non_pred_all:\n",
    "    plt.plot(er[0], label=er[1])\n",
    "\n",
    "plt.plot(non_pred_res, label='tube')\n",
    "plt.grid()\n",
    "plt.title('RMSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TENewchM082e"
   },
   "source": [
    "## plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kv6TLqFOxJcX"
   },
   "outputs": [],
   "source": [
    "p_norm = p / np.sum(p)\n",
    "res_trajectory = trajectories.T.dot(p_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQG46mMrsCU0"
   },
   "outputs": [],
   "source": [
    "# RAND_CL_AM = 1\n",
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'mix')\n",
    "                 ],\n",
    "                20,\n",
    "                real_vals=x_val,\n",
    "                plot_tube_points=trajectories,\n",
    "                plot_res_tube=res_trajectory\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9r6xhqGTH-h"
   },
   "outputs": [],
   "source": [
    "# RAND_CL_AM = 3\n",
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'mix')\n",
    "                 ],\n",
    "                20,\n",
    "                real_vals=x_val,\n",
    "                plot_tube_points=trajectories,\n",
    "                plot_res_tube=res_trajectory\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTzILi6-vdxc"
   },
   "outputs": [],
   "source": [
    "# RAND_CL_AM = 5\n",
    "visualize_point([\n",
    "                 (Simple_deamon_mix_val, 'mix')\n",
    "                 ],\n",
    "                20,\n",
    "                real_vals=x_val,\n",
    "                plot_tube_points=trajectories,\n",
    "                plot_res_tube=res_trajectory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFl-xNh7Js5m"
   },
   "source": [
    "# 9 Save session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmPPpToyMF8X"
   },
   "outputs": [],
   "source": [
    "path_to_save_session = 'last_env.db'\n",
    "\n",
    "if save_session:\n",
    "    dill.dump_session(path_to_save_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v15YwxXsNrrL"
   },
   "outputs": [],
   "source": [
    "! mv 'last_env.db' '/content/drive/My Drive'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vUO5luGMMF5R",
    "EMMOk0wPMF5g",
    "lDHLmrg40qtl",
    "NCqBKw-cMF5t",
    "EDUqMzWNMF51",
    "RfJ07uSRMF59",
    "qwLoBCbViUdd",
    "BZcurf-HlLIq",
    "4zB5eyJIMF73",
    "LNk9YhFfF7V5",
    "1UDN0i6QcgKs",
    "pqQQtSDdlNM1",
    "AN22mZgUlbEo",
    "S1qZ_Ix5suFF",
    "su3r-uIxZVaj",
    "xfsIC8Nt4EVN",
    "4kdXIVMLVQXt",
    "8uRjlI7zvzud",
    "QHa54VfgcHNs",
    "fXOeQtKAMF6W",
    "TaHq2HJrMvJR",
    "ZTUnDoil3tBz",
    "GvSYRYVUT_S7",
    "Mj9SRUrf33sa",
    "cN_l3Nvr44Sl",
    "ccp7N0iaMF7q",
    "sKnmo7kWfZtR",
    "0GlJQ080fcZB",
    "7dqYwNXNf0Mq",
    "7GMtfrv5f21x",
    "UlhhvKjChqWJ",
    "f2H5wLygiGBr",
    "Y8tmcy6eRG96",
    "DWZOR1ZlQPZ9",
    "iwKcRAVI-bdg",
    "DEkSI_KmUbgT",
    "9WHb5hBzVOg4",
    "gBI_MF6l_Y4p",
    "mCNEwpiiZsGY",
    "h-wp9ovYgWml",
    "1Ra9HtxiWgy5",
    "qf7C1YA9Lh4p",
    "HTrs7hkbLpsX",
    "yEDB2oT_LvSG",
    "gRtxJL-33ld4",
    "ML-bLhKCHVdU",
    "ZooNq8XAUWJb",
    "Mr1Df5I3T8si",
    "e-E2TRxFkrXX",
    "m7obi2x2kuEJ",
    "2SxSwn60lwzc",
    "xOMvCGsAk2GW",
    "lNX0jVghndHH",
    "i8aGfmDlLSNU",
    "nNKV6l7OLZiq",
    "jLeeLUXZL-hN",
    "f5YDAEoGMFcx",
    "kK-69p-MMMj4",
    "G7mfD3A9MQcn",
    "oCFcJ7avMXCf",
    "juyNWG8OMcBj",
    "Pv2y_1xCwFT9",
    "Enh6v5URIbuI",
    "VAQNiuavTxeU"
   ],
   "machine_shape": "hm",
   "name": "Lorenz_forecasting.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
